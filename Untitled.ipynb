{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement...\n",
      "1 is Incorrectly Recognized as 21\n",
      "1  is Correctly Recognized with confidence 79.11057948682627\n",
      "1  is Correctly Recognized with confidence 78.76698541956233\n",
      "1 is Incorrectly Recognized as 24\n",
      "10 is Incorrectly Recognized as 40\n",
      "10  is Correctly Recognized with confidence 55.20062232282382\n",
      "10  is Correctly Recognized with confidence 66.40613131290756\n",
      "10  is Correctly Recognized with confidence 51.454738817386534\n",
      "11  is Correctly Recognized with confidence 62.410818342396134\n",
      "11  is Correctly Recognized with confidence 48.554299452153856\n",
      "11  is Correctly Recognized with confidence 65.00781632276748\n",
      "11  is Correctly Recognized with confidence 76.14044790381118\n",
      "11  is Correctly Recognized with confidence 61.859719788074344\n",
      "12  is Correctly Recognized with confidence 63.15618388534599\n",
      "12  is Correctly Recognized with confidence 60.46481307003081\n",
      "12  is Correctly Recognized with confidence 47.31225766447047\n",
      "12  is Correctly Recognized with confidence 58.160347006470445\n",
      "12  is Correctly Recognized with confidence 53.61572657860422\n",
      "13  is Correctly Recognized with confidence 60.13388418856239\n",
      "13  is Correctly Recognized with confidence 82.99130691234433\n",
      "13  is Correctly Recognized with confidence 74.35979471561934\n",
      "13  is Correctly Recognized with confidence 65.93114579425969\n",
      "13  is Correctly Recognized with confidence 64.49798635517828\n",
      "14  is Correctly Recognized with confidence 58.60007795166386\n",
      "14  is Correctly Recognized with confidence 49.88656683299543\n",
      "14  is Correctly Recognized with confidence 57.57652078174319\n",
      "14  is Correctly Recognized with confidence 53.9153182716777\n",
      "14  is Correctly Recognized with confidence 56.07943471243681\n",
      "15  is Correctly Recognized with confidence 52.79526623536232\n",
      "15  is Correctly Recognized with confidence 54.7043518896669\n",
      "15  is Correctly Recognized with confidence 58.08532031804243\n",
      "15  is Correctly Recognized with confidence 67.50417124367088\n",
      "15  is Correctly Recognized with confidence 52.20090733874953\n",
      "16  is Correctly Recognized with confidence 49.79066828344197\n",
      "16  is Correctly Recognized with confidence 78.81081543608104\n",
      "16  is Correctly Recognized with confidence 72.81120814123321\n",
      "17  is Correctly Recognized with confidence 79.86518749377794\n",
      "17  is Correctly Recognized with confidence 71.09852075990136\n",
      "17  is Correctly Recognized with confidence 75.26258297980323\n",
      "18  is Correctly Recognized with confidence 58.681772921636416\n",
      "18  is Correctly Recognized with confidence 59.53634039815388\n",
      "18  is Correctly Recognized with confidence 67.289690582416\n",
      "18  is Correctly Recognized with confidence 56.65984383037787\n",
      "18  is Correctly Recognized with confidence 64.99015923968658\n",
      "19  is Correctly Recognized with confidence 45.02613638890017\n",
      "19  is Correctly Recognized with confidence 62.660667047471186\n",
      "19  is Correctly Recognized with confidence 58.76941097035565\n",
      "19  is Correctly Recognized with confidence 50.659176047540114\n",
      "19  is Correctly Recognized with confidence 54.383169797314395\n",
      "2  is Correctly Recognized with confidence 57.79132112165252\n",
      "2  is Correctly Recognized with confidence 59.48087442083161\n",
      "2  is Correctly Recognized with confidence 64.43285815610352\n",
      "2  is Correctly Recognized with confidence 56.192095561393614\n",
      "2  is Correctly Recognized with confidence 63.62410565593685\n",
      "20  is Correctly Recognized with confidence 59.45262099920703\n",
      "20  is Correctly Recognized with confidence 56.69003331161071\n",
      "20  is Correctly Recognized with confidence 51.730962296158985\n",
      "20  is Correctly Recognized with confidence 48.89968562165442\n",
      "20  is Correctly Recognized with confidence 52.481360397816026\n",
      "21  is Correctly Recognized with confidence 66.87838041723022\n",
      "21  is Correctly Recognized with confidence 47.58956887851063\n",
      "21  is Correctly Recognized with confidence 63.897192051947854\n",
      "21  is Correctly Recognized with confidence 77.58520137261993\n",
      "21  is Correctly Recognized with confidence 66.0327479832436\n",
      "22  is Correctly Recognized with confidence 58.58179299328525\n",
      "22  is Correctly Recognized with confidence 67.80606541473603\n",
      "22  is Correctly Recognized with confidence 53.96143033066663\n",
      "22  is Correctly Recognized with confidence 56.137995654402175\n",
      "22  is Correctly Recognized with confidence 58.013164075221795\n",
      "23  is Correctly Recognized with confidence 57.13915799159763\n",
      "23  is Correctly Recognized with confidence 52.36801983699759\n",
      "23  is Correctly Recognized with confidence 47.92975620851623\n",
      "23  is Correctly Recognized with confidence 44.45498487078926\n",
      "23 is Incorrectly Recognized as 38\n",
      "24  is Correctly Recognized with confidence 64.07930173633851\n",
      "24  is Correctly Recognized with confidence 58.13525031900399\n",
      "24  is Correctly Recognized with confidence 59.555002910410366\n",
      "24  is Correctly Recognized with confidence 66.78642719085337\n",
      "24  is Correctly Recognized with confidence 61.297698188223094\n",
      "25  is Correctly Recognized with confidence 51.7345180828929\n",
      "25  is Correctly Recognized with confidence 61.35077242530309\n",
      "25  is Correctly Recognized with confidence 48.46247484650315\n",
      "25  is Correctly Recognized with confidence 69.62089977788251\n",
      "26  is Correctly Recognized with confidence 59.97017002328678\n",
      "26 is Incorrectly Recognized as 28\n",
      "26 is Incorrectly Recognized as 3\n",
      "26  is Correctly Recognized with confidence 58.029080495541145\n",
      "27  is Correctly Recognized with confidence 58.62968333989068\n",
      "27  is Correctly Recognized with confidence 56.880805233172765\n",
      "27  is Correctly Recognized with confidence 60.51703076510031\n",
      "27  is Correctly Recognized with confidence 52.497204633752546\n",
      "27  is Correctly Recognized with confidence 64.09916702854927\n",
      "28  is Correctly Recognized with confidence 50.89422474043253\n",
      "28  is Correctly Recognized with confidence 54.79441548316196\n",
      "28 is Incorrectly Recognized as 4\n",
      "28  is Correctly Recognized with confidence 71.04654895990522\n",
      "29  is Correctly Recognized with confidence 56.9451119596442\n",
      "29  is Correctly Recognized with confidence 47.368411043486134\n",
      "29  is Correctly Recognized with confidence 47.69439524471326\n",
      "29  is Correctly Recognized with confidence 61.052246464116784\n",
      "3  is Correctly Recognized with confidence 69.09609772784863\n",
      "3 is Incorrectly Recognized as 12\n",
      "3  is Correctly Recognized with confidence 78.49043892223344\n",
      "3 is Incorrectly Recognized as 10\n",
      "3  is Correctly Recognized with confidence 68.96278689241178\n",
      "30  is Correctly Recognized with confidence 52.65313732052856\n",
      "30  is Correctly Recognized with confidence 62.17094058402482\n",
      "30  is Correctly Recognized with confidence 68.48166484814723\n",
      "30  is Correctly Recognized with confidence 64.88436917060572\n",
      "30  is Correctly Recognized with confidence 79.68021665348303\n",
      "31  is Correctly Recognized with confidence 65.15223166072812\n",
      "31  is Correctly Recognized with confidence 58.15138446921656\n",
      "31  is Correctly Recognized with confidence 78.75253304531819\n",
      "31  is Correctly Recognized with confidence 42.427856582933714\n",
      "31  is Correctly Recognized with confidence 65.08348526636925\n",
      "32  is Correctly Recognized with confidence 64.24045616506383\n",
      "32  is Correctly Recognized with confidence 63.18304929591173\n",
      "32  is Correctly Recognized with confidence 65.92600509871689\n",
      "32  is Correctly Recognized with confidence 63.85192158455343\n",
      "33  is Correctly Recognized with confidence 51.283112028892475\n",
      "33  is Correctly Recognized with confidence 89.50493775356539\n",
      "33  is Correctly Recognized with confidence 61.49641366013648\n",
      "33  is Correctly Recognized with confidence 70.49965836609795\n",
      "33  is Correctly Recognized with confidence 56.383198854015326\n",
      "34  is Correctly Recognized with confidence 64.66896087294303\n",
      "34  is Correctly Recognized with confidence 58.06411955042249\n",
      "34  is Correctly Recognized with confidence 55.49359984225428\n",
      "34  is Correctly Recognized with confidence 69.78890097076481\n",
      "35 is Incorrectly Recognized as 13\n",
      "35  is Correctly Recognized with confidence 72.2686042812428\n",
      "35  is Correctly Recognized with confidence 76.78891220126144\n",
      "35  is Correctly Recognized with confidence 69.28602189021105\n",
      "36  is Correctly Recognized with confidence 73.56441441389376\n",
      "36  is Correctly Recognized with confidence 57.214325624488175\n",
      "36  is Correctly Recognized with confidence 49.80728394594327\n",
      "36  is Correctly Recognized with confidence 70.86847441224793\n",
      "37  is Correctly Recognized with confidence 62.727532479414066\n",
      "37  is Correctly Recognized with confidence 63.04760713862888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37  is Correctly Recognized with confidence 70.30303316952983\n",
      "37  is Correctly Recognized with confidence 56.90491235286671\n",
      "37  is Correctly Recognized with confidence 53.276524183755924\n",
      "38  is Correctly Recognized with confidence 53.65959692432739\n",
      "38  is Correctly Recognized with confidence 46.8103814006879\n",
      "38  is Correctly Recognized with confidence 47.843048240919565\n",
      "38  is Correctly Recognized with confidence 60.01476415587033\n",
      "38  is Correctly Recognized with confidence 51.70660902100398\n",
      "39  is Correctly Recognized with confidence 91.31313425322729\n",
      "39  is Correctly Recognized with confidence 90.94314856554357\n",
      "39  is Correctly Recognized with confidence 61.15818100969368\n",
      "4  is Correctly Recognized with confidence 82.66019577845869\n",
      "4  is Correctly Recognized with confidence 52.50974866841058\n",
      "4  is Correctly Recognized with confidence 47.38380163867941\n",
      "4  is Correctly Recognized with confidence 59.75955335002429\n",
      "40  is Correctly Recognized with confidence 78.16832684904686\n",
      "40  is Correctly Recognized with confidence 63.62825408625016\n",
      "40  is Correctly Recognized with confidence 74.29816464262065\n",
      "40  is Correctly Recognized with confidence 48.31870581742671\n",
      "40  is Correctly Recognized with confidence 97.79436889486237\n",
      "5 is Incorrectly Recognized as 40\n",
      "5  is Correctly Recognized with confidence 58.79469451292271\n",
      "5  is Correctly Recognized with confidence 73.43420073105285\n",
      "5  is Correctly Recognized with confidence 72.24251609186581\n",
      "6  is Correctly Recognized with confidence 51.46181488042079\n",
      "6  is Correctly Recognized with confidence 58.8748190977963\n",
      "6  is Correctly Recognized with confidence 54.70621875496058\n",
      "6  is Correctly Recognized with confidence 69.58710639888697\n",
      "6  is Correctly Recognized with confidence 80.554937014759\n",
      "7  is Correctly Recognized with confidence 62.612414434641536\n",
      "7  is Correctly Recognized with confidence 52.54224371466027\n",
      "7  is Correctly Recognized with confidence 53.33730714358748\n",
      "7  is Correctly Recognized with confidence 58.89636094200562\n",
      "7  is Correctly Recognized with confidence 55.8046710654429\n",
      "8  is Correctly Recognized with confidence 63.6274424430192\n",
      "8  is Correctly Recognized with confidence 49.570975203574854\n",
      "8  is Correctly Recognized with confidence 59.02411164410093\n",
      "8  is Correctly Recognized with confidence 47.524764537687396\n",
      "8  is Correctly Recognized with confidence 68.28438568928195\n",
      "9  is Correctly Recognized with confidence 62.709508508133915\n",
      "9  is Correctly Recognized with confidence 61.118471555781774\n",
      "9 is Incorrectly Recognized as 3\n",
      "9  is Correctly Recognized with confidence 55.62714329702383\n",
      "9  is Correctly Recognized with confidence 48.50989298761204\n",
      "Taux de bon classement 0.9340659340659341\n"
     ]
    }
   ],
   "source": [
    "# %load reconnaissance.py\n",
    "# %load reconnaissance.py\n",
    "\n",
    "\n",
    "import cv2, sys, numpy, os\n",
    "from PIL import Image\n",
    "size = 1\n",
    "fn_haar = 'haarcascade_frontalface_default.xml'\n",
    "fn_dir = 'att_faces'\n",
    "fn_dir_test = 'test'\n",
    "# Part 1: Create LBPH\n",
    "print('Entrainement...')\n",
    "haar_cascade = cv2.CascadeClassifier(fn_haar)\n",
    "# Create a list of images and a list of corresponding names\n",
    "(images, lables, names, id) = ([], [], {}, 0)\n",
    "(im_width, im_height) = (112, 92)\n",
    "# Get the folders containing the training data\n",
    "for (subdirs, dirs, files) in os.walk(fn_dir):\n",
    "\n",
    "    # Loop through each folder named after the subject in the photos\n",
    "    for subdir in dirs:\n",
    "        names[id] = subdir\n",
    "        subjectpath = os.path.join(fn_dir, subdir)\n",
    "\n",
    "        # Loop through each photo in the folder\n",
    "        for filename in os.listdir(subjectpath):\n",
    "\n",
    "            # Skip non-image formates\n",
    "            f_name, f_extension = os.path.splitext(filename)\n",
    "            if(f_extension.lower() not in\n",
    "                    ['.png','.jpg','.jpeg','.gif','.pgm']):\n",
    "                print(\"Sauter \"+filename+\", mauvais type de fichier\")\n",
    "                continue\n",
    "            path = subjectpath + '/' + filename\n",
    "            lable = id\n",
    "            nbr = f_name\n",
    "            image = Image.open(path).convert('L')\n",
    "            image = numpy.array(image, 'uint8')\n",
    "            # Add to training data\n",
    "            faces = haar_cascade.detectMultiScale(image)\n",
    "            for (x, y, w, h) in faces: \n",
    "                images.append( cv2.resize(image[y: y + h, x: x + w], (im_width, im_height))) \n",
    "                classe=int(subdir.replace(\"s\",\"\"))\n",
    "                lables.append(classe)\n",
    "                #print (subdir,\"---\")\n",
    "            \n",
    "           \n",
    "            #images.append(cv2.imread(path, 0))\n",
    "            #lables.append(int(lable))\n",
    "           \n",
    "        id += 1\n",
    "\n",
    "\n",
    "# Create a Numpy array from the two lists above\n",
    "(images, lables) = [numpy.array(lis) for lis in [images, lables]]\n",
    "\n",
    "# OpenCV trains a model from the images\n",
    "# NOTE FOR OpenCV2: remove '.face'\n",
    "model = cv2.face.createLBPHFaceRecognizer()\n",
    "#model = cv2.face.createFisherFaceRecognizer()\n",
    "model.train(images, numpy.array(lables))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Part 3: test and calculate error\n",
    "bon=0\n",
    "tous=0\n",
    "\n",
    "# Get the folders containing the training data\n",
    "for (subdirs1, dirs1, files1) in os.walk(fn_dir_test):\n",
    "\n",
    "    # Loop through each folder named after the subject in the photos\n",
    "    for subdir1 in dirs1:\n",
    "        subjectpath1 = os.path.join(fn_dir_test, subdir1)\n",
    "\n",
    "        # Loop through each photo in the folder\n",
    "        for filename1 in os.listdir(subjectpath1):\n",
    "\n",
    "            # Skip non-image formates\n",
    "            f_name1, f_extension1 = os.path.splitext(filename1)\n",
    "            if(f_extension1.lower() not in\n",
    "                    ['.png','.jpg','.jpeg','.gif','.pgm']):\n",
    "                print(\"Sauter \"+filename+\", mauvais type de fichier\")\n",
    "                continue\n",
    "            path1 = subjectpath1 + '/' + filename1\n",
    "            #loading the image and converting it to gray scale\n",
    "            image1=Image.open(path1).convert('L')\n",
    "            #Now we are converting the PIL image into numpy array\n",
    "            image1=numpy.array(image1,'uint8')\n",
    "            #image1 = cv2.imread(path1)\n",
    "             # Convert to grayscalel\n",
    "           # gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "            # Resize to speed up detection (optinal, change size above)\n",
    "            #mini1 = cv2.resize(gray1, (int(gray1.shape[1] / size), int(gray1.shape[0] / size)))\n",
    "            # Detect faces and loop through each one\n",
    "            faces1 = haar_cascade.detectMultiScale(image1)\n",
    "            \n",
    "            for (x, y, w, h) in faces1:\n",
    "                # Coordinates of face after scaling back by `size`\n",
    "                face1 = image1[y:y + h, x:x + w]\n",
    "                face_resize1 = cv2.resize(face1, (im_width, im_height))\n",
    "                # Try to recognize the face\n",
    "                #model.predict(face1)\n",
    "                nbr_predicted, conf = model.predict(face_resize1)\n",
    "                nbr_actual = int(subdir1.replace(\"s\",\"\"))\n",
    "                if nbr_actual == nbr_predicted:\n",
    "                    print (nbr_actual,\" is Correctly Recognized with confidence\",conf)\n",
    "                    bon = bon + 1\n",
    "                else:\n",
    "                    print (nbr_actual,\"is Incorrectly Recognized as\",nbr_predicted)\n",
    "                tous = tous + 1\n",
    "print (\"Taux de bon classement\",bon/tous)\n",
    "    # Show the image and check for ESC being pressed\n",
    "#cv2.imshow('Reconnaissance', image1)\n",
    "#cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement...\n",
      "5\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-ca42c0e3d7cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;31m# Add to training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mfacePoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhaar_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfacePoints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfacePoints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# %load cnn.py\n",
    "import cv2\n",
    "import numpy\n",
    "import os\n",
    "from skimage import io\n",
    "from sklearn.model_selection import train_test_split \n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "size = 1\n",
    "fn_haar = 'haarcascade_frontalface_default.xml'\n",
    "fn_dir = 'att_faces'\n",
    "fn_dir_test = 'test'\n",
    "# Part 1: Create LBPH\n",
    "print('Entrainement...')\n",
    "haar_cascade = cv2.CascadeClassifier(fn_haar)\n",
    "# Create a list of images and a list of corresponding names\n",
    "(images1,images, lables, names, id) = ([], [], [], {}, 0)\n",
    "\n",
    "# Get the folders containing the training data\n",
    "for (subdirs, dirs, files) in os.walk(fn_dir):\n",
    "\n",
    "    # Loop through each folder named after the subject in the photos\n",
    "    for subdir in dirs:\n",
    "        names[id] = subdir\n",
    "        subjectpath = os.path.join(fn_dir, subdir)\n",
    "        \n",
    "#Reading each image and assigning respective label \n",
    "        # Loop through each photo in the folder\n",
    "        for filename in os.listdir(subjectpath):\n",
    "\n",
    "            # Skip non-image formates\n",
    "            f_name, f_extension = os.path.splitext(filename)\n",
    "            if(f_extension.lower() not in\n",
    "                    ['.png','.jpg','.jpeg','.gif','.pgm']):\n",
    "                print(\"Sauter \"+filename+\", mauvais type de fichier\")\n",
    "                continue\n",
    "            path = subjectpath + '/' + filename\n",
    "            lable = id\n",
    "            nbr = f_name\n",
    "            image = io.imread(path, as_grey=True)\n",
    "            # Add to training data\n",
    "            facePoints = haar_cascade.detectMultiScale(image)\n",
    "            print(facePoints[0][0])\n",
    "            x,y = facePoints[0][:2]\n",
    "            \n",
    "            cropped = image[y: y + 150, x: x + 150]\n",
    "            images.append(cropped)           \n",
    "        id += 1\n",
    "\n",
    "nb_classes = id\n",
    "# Create a Numpy array from the two lists above\n",
    "(images, lables) = [numpy.array(lis) for lis in [images, lables]]\n",
    "images = images.reshape(200, 150*150)\n",
    "#Splitting Dataset into train and test\n",
    "lables = np_utils.to_categorical(lables, nb_classes)\n",
    "images = X_train.astype('float32')\n",
    "images /= 255\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512,input_shape=(X_train.shape[1],)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.fit(images, lables, batch_size=64, nb_epoch=50, verbose=1)\n",
    "\n",
    "# Part 3: test and calculate error\n",
    "bon=0\n",
    "tous=0\n",
    "k=0\n",
    "# Get the folders containing the training data\n",
    "for (subdirs1, dirs1, files1) in os.walk(fn_dir_test):\n",
    "\n",
    "    # Loop through each folder named after the subject in the photos\n",
    "    for subdir1 in dirs1:\n",
    "        subjectpath1 = os.path.join(fn_dir_test, subdir1)\n",
    "\n",
    "        # Loop through each photo in the folder\n",
    "        for filename1 in os.listdir(subjectpath1):\n",
    "\n",
    "            # Skip non-image formates\n",
    "            f_name1, f_extension1 = os.path.splitext(filename1)\n",
    "            if(f_extension1.lower() not in\n",
    "                    ['.png','.jpg','.jpeg','.gif','.pgm']):\n",
    "                print(\"Sauter \"+filename+\", mauvais type de fichier\")\n",
    "                continue\n",
    "            path1 = subjectpath1 + '/' + filename1\n",
    "            nbr_actual = int(subdir1.replace(\"s\",\"\"))\n",
    "            #loading the image and converting it to gray scale\n",
    "            image1=Image.open(path1).convert('L')\n",
    "            #Now we are converting the PIL image into numpy array\n",
    "            image1=numpy.array(image1,'uint8')\n",
    "            faces1 = haar_cascade.detectMultiScale(image1)\n",
    "            x,y = faces1[0][:2]\n",
    "            cropped1 = image1[y: y + 150, x: x + 150]\n",
    "            images1.append(cropped1)\n",
    "            lable1.append(nbr_actual)\n",
    "images1=numpy.array(images1)\n",
    "images1 = images1.reshape(200, 150*150)\n",
    "images1 = images1.astype('float32')\n",
    "images1 /= 255\n",
    "for i in images1:\n",
    "    preds = model.predict(i)\n",
    "    nbr_predicted=np.argmax(preds[0])\n",
    "    nbr_actual = int(lable1[k])\n",
    "    if nbr_actual == nbr_predicted:\n",
    "        print (nbr_actual,\" is Correctly Recognized \")\n",
    "        bon = bon + 1\n",
    "    else:\n",
    "        print (nbr_actual,\"is Incorrectly Recognized \")\n",
    "        tous = tous + 1\n",
    "    k = k +1\n",
    "print (\"Taux de bon classement\",bon/tous)\n",
    "    # Show the image and check for ESC being pressed\n",
    "#cv2.imshow('Reconnaissance', image1)\n",
    "#cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load cnn.py\n",
    "import cv2\n",
    "import numpy\n",
    "import os\n",
    "from skimage import io\n",
    "from sklearn.model_selection import train_test_split \n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "size = 1\n",
    "fn_haar = 'haarcascade_frontalface_default.xml'\n",
    "fn_dir = 'att_faces'\n",
    "fn_dir_test = 'test'\n",
    "# Part 1: Create LBPH\n",
    "print('Entrainement...')\n",
    "haar_cascade = cv2.CascadeClassifier(fn_haar)\n",
    "# Create a list of images and a list of corresponding names\n",
    "(images1,images, lables, names, id) = ([], [], [], {}, 0)\n",
    "\n",
    "# Get the folders containing the training data\n",
    "for (subdirs, dirs, files) in os.walk(fn_dir):\n",
    "\n",
    "    # Loop through each folder named after the subject in the photos\n",
    "    for subdir in dirs:\n",
    "        names[id] = subdir\n",
    "        subjectpath = os.path.join(fn_dir, subdir)\n",
    "        \n",
    "#Reading each image and assigning respective label \n",
    "        # Loop through each photo in the folder\n",
    "        for filename in os.listdir(subjectpath):\n",
    "\n",
    "            # Skip non-image formates\n",
    "            f_name, f_extension = os.path.splitext(filename)\n",
    "            if(f_extension.lower() not in\n",
    "                    ['.png','.jpg','.jpeg','.gif','.pgm']):\n",
    "                print(\"Sauter \"+filename+\", mauvais type de fichier\")\n",
    "                continue\n",
    "            path = subjectpath + '/' + filename\n",
    "            lable = id\n",
    "            nbr = f_name\n",
    "            image = io.imread(path, as_grey=True)\n",
    "            # Add to training data\n",
    "            facePoints = haar_cascade.detectMultiScale(image)\n",
    "            print(facePoints[0][0])\n",
    "            x,y = facePoints[0][:2]\n",
    "            \n",
    "            cropped = image[y: y + 150, x: x + 150]\n",
    "            images.append(cropped)           \n",
    "        id += 1\n",
    "\n",
    "nb_classes = id\n",
    "# Create a Numpy array from the two lists above\n",
    "(images, lables) = [numpy.array(lis) for lis in [images, lables]]\n",
    "images = images.reshape(200, 150*150)\n",
    "#Splitting Dataset into train and test\n",
    "lables = np_utils.to_categorical(lables, nb_classes)\n",
    "images = X_train.astype('float32')\n",
    "images /= 255\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512,input_shape=(X_train.shape[1],)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.fit(images, lables, batch_size=64, nb_epoch=50, verbose=1)\n",
    "\n",
    "# Part 3: test and calculate error\n",
    "bon=0\n",
    "tous=0\n",
    "k=0\n",
    "# Get the folders containing the training data\n",
    "for (subdirs1, dirs1, files1) in os.walk(fn_dir_test):\n",
    "\n",
    "    # Loop through each folder named after the subject in the photos\n",
    "    for subdir1 in dirs1:\n",
    "        subjectpath1 = os.path.join(fn_dir_test, subdir1)\n",
    "\n",
    "        # Loop through each photo in the folder\n",
    "        for filename1 in os.listdir(subjectpath1):\n",
    "\n",
    "            # Skip non-image formates\n",
    "            f_name1, f_extension1 = os.path.splitext(filename1)\n",
    "            if(f_extension1.lower() not in\n",
    "                    ['.png','.jpg','.jpeg','.gif','.pgm']):\n",
    "                print(\"Sauter \"+filename+\", mauvais type de fichier\")\n",
    "                continue\n",
    "            path1 = subjectpath1 + '/' + filename1\n",
    "            nbr_actual = int(subdir1.replace(\"s\",\"\"))\n",
    "            #loading the image and converting it to gray scale\n",
    "            image1=Image.open(path1).convert('L')\n",
    "            #Now we are converting the PIL image into numpy array\n",
    "            image1=numpy.array(image1,'uint8')\n",
    "            faces1 = haar_cascade.detectMultiScale(image1)\n",
    "            x,y = faces1[0][:2]\n",
    "            cropped1 = image1[y: y + 150, x: x + 150]\n",
    "            images1.append(cropped1)\n",
    "            lable1.append(nbr_actual)\n",
    "images1=numpy.array(images1)\n",
    "images1 = images1.reshape(200, 150*150)\n",
    "images1 = images1.astype('float32')\n",
    "images1 /= 255\n",
    "for i in images1:\n",
    "    preds = model.predict(i)\n",
    "    nbr_predicted=np.argmax(preds[0])\n",
    "    nbr_actual = int(lable1[k])\n",
    "    if nbr_actual == nbr_predicted:\n",
    "        print (nbr_actual,\" is Correctly Recognized \")\n",
    "        bon = bon + 1\n",
    "    else:\n",
    "        print (nbr_actual,\"is Incorrectly Recognized \")\n",
    "        tous = tous + 1\n",
    "    k = k +1\n",
    "print (\"Taux de bon classement\",bon/tous)\n",
    "    # Show the image and check for ESC being pressed\n",
    "#cv2.imshow('Reconnaissance', image1)\n",
    "#cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7069d4b04c90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[1;31m#print(facePoints[0][0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[1;31m#x,y = facePoints[0][:2]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfacePoints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfacePoints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mcropped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# %load cnn.py\n",
    "import cv2\n",
    "import numpy\n",
    "import os\n",
    "from skimage import io\n",
    "from sklearn.model_selection import train_test_split \n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "size = 1\n",
    "fn_haar = 'haarcascade_frontalface_default.xml'\n",
    "fn_dir = 'att_faces'\n",
    "fn_dir_test = 'test'\n",
    "# Part 1: Create LBPH\n",
    "print('Entrainement...')\n",
    "haar_cascade = cv2.CascadeClassifier(fn_haar)\n",
    "# Create a list of images and a list of corresponding names\n",
    "(images1,images, lables, names, id) = ([], [], [], {}, 0)\n",
    "\n",
    "# Get the folders containing the training data\n",
    "for (subdirs, dirs, files) in os.walk(fn_dir):\n",
    "\n",
    "    # Loop through each folder named after the subject in the photos\n",
    "    for subdir in dirs:\n",
    "        names[id] = subdir\n",
    "        subjectpath = os.path.join(fn_dir, subdir)\n",
    "        \n",
    "#Reading each image and assigning respective label \n",
    "        # Loop through each photo in the folder\n",
    "        for filename in os.listdir(subjectpath):\n",
    "\n",
    "            # Skip non-image formates\n",
    "            f_name, f_extension = os.path.splitext(filename)\n",
    "            if(f_extension.lower() not in\n",
    "                    ['.png','.jpg','.jpeg','.gif','.pgm']):\n",
    "                print(\"Sauter \"+filename+\", mauvais type de fichier\")\n",
    "                continue\n",
    "            path = subjectpath + '/' + filename\n",
    "            lable = id\n",
    "            nbr = f_name\n",
    "            image = io.imread(path, as_grey=True)\n",
    "            # Add to training data\n",
    "            facePoints = haar_cascade.detectMultiScale(image)\n",
    "            #print(facePoints[0][0])\n",
    "            #x,y = facePoints[0][:2]\n",
    "            x=facePoints[0][0]\n",
    "            y=facePoints[0][1]\n",
    "            cropped = image[y: y + 150, x: x + 150]\n",
    "            images.append(cropped)           \n",
    "        id += 1\n",
    "\n",
    "nb_classes = id\n",
    "# Create a Numpy array from the two lists above\n",
    "(images, lables) = [numpy.array(lis) for lis in [images, lables]]\n",
    "images = images.reshape(200, 150*150)\n",
    "#Splitting Dataset into train and test\n",
    "lables = np_utils.to_categorical(lables, nb_classes)\n",
    "images = X_train.astype('float32')\n",
    "images /= 255\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512,input_shape=(X_train.shape[1],)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.fit(images, lables, batch_size=64, nb_epoch=50, verbose=1)\n",
    "\n",
    "# Part 3: test and calculate error\n",
    "bon=0\n",
    "tous=0\n",
    "k=0\n",
    "# Get the folders containing the training data\n",
    "for (subdirs1, dirs1, files1) in os.walk(fn_dir_test):\n",
    "\n",
    "    # Loop through each folder named after the subject in the photos\n",
    "    for subdir1 in dirs1:\n",
    "        subjectpath1 = os.path.join(fn_dir_test, subdir1)\n",
    "\n",
    "        # Loop through each photo in the folder\n",
    "        for filename1 in os.listdir(subjectpath1):\n",
    "\n",
    "            # Skip non-image formates\n",
    "            f_name1, f_extension1 = os.path.splitext(filename1)\n",
    "            if(f_extension1.lower() not in\n",
    "                    ['.png','.jpg','.jpeg','.gif','.pgm']):\n",
    "                print(\"Sauter \"+filename+\", mauvais type de fichier\")\n",
    "                continue\n",
    "            path1 = subjectpath1 + '/' + filename1\n",
    "            nbr_actual = int(subdir1.replace(\"s\",\"\"))\n",
    "            #loading the image and converting it to gray scale\n",
    "            image1=Image.open(path1).convert('L')\n",
    "            #Now we are converting the PIL image into numpy array\n",
    "            image1=numpy.array(image1,'uint8')\n",
    "            faces1 = haar_cascade.detectMultiScale(image1)\n",
    "            x,y = faces1[0][:2]\n",
    "            cropped1 = image1[y: y + 150, x: x + 150]\n",
    "            images1.append(cropped1)\n",
    "            lable1.append(nbr_actual)\n",
    "images1=numpy.array(images1)\n",
    "images1 = images1.reshape(200, 150*150)\n",
    "images1 = images1.astype('float32')\n",
    "images1 /= 255\n",
    "for i in images1:\n",
    "    preds = model.predict(i)\n",
    "    nbr_predicted=np.argmax(preds[0])\n",
    "    nbr_actual = int(lable1[k])\n",
    "    if nbr_actual == nbr_predicted:\n",
    "        print (nbr_actual,\" is Correctly Recognized \")\n",
    "        bon = bon + 1\n",
    "    else:\n",
    "        print (nbr_actual,\"is Incorrectly Recognized \")\n",
    "        tous = tous + 1\n",
    "    k = k +1\n",
    "print (\"Taux de bon classement\",bon/tous)\n",
    "    # Show the image and check for ESC being pressed\n",
    "#cv2.imshow('Reconnaissance', image1)\n",
    "#cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement...\n",
      "5\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-861e348a9a22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;31m# Add to training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mfacePoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhaar_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfacePoints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfacePoints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mcropped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# %load cnn.py\n",
    "import cv2\n",
    "import numpy\n",
    "import os\n",
    "from skimage import io\n",
    "from sklearn.model_selection import train_test_split \n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "size = 1\n",
    "fn_haar = 'haarcascade_frontalface_default.xml'\n",
    "fn_dir = 'att_faces'\n",
    "fn_dir_test = 'test'\n",
    "# Part 1: Create LBPH\n",
    "print('Entrainement...')\n",
    "haar_cascade = cv2.CascadeClassifier(fn_haar)\n",
    "# Create a list of images and a list of corresponding names\n",
    "(images1,images, lables, names, id) = ([], [], [], {}, 0)\n",
    "\n",
    "# Get the folders containing the training data\n",
    "for (subdirs, dirs, files) in os.walk(fn_dir):\n",
    "\n",
    "    # Loop through each folder named after the subject in the photos\n",
    "    for subdir in dirs:\n",
    "        names[id] = subdir\n",
    "        subjectpath = os.path.join(fn_dir, subdir)\n",
    "        \n",
    "#Reading each image and assigning respective label \n",
    "        # Loop through each photo in the folder\n",
    "        for filename in os.listdir(subjectpath):\n",
    "\n",
    "            # Skip non-image formates\n",
    "            f_name, f_extension = os.path.splitext(filename)\n",
    "            if(f_extension.lower() not in\n",
    "                    ['.png','.jpg','.jpeg','.gif','.pgm']):\n",
    "                print(\"Sauter \"+filename+\", mauvais type de fichier\")\n",
    "                continue\n",
    "            path = subjectpath + '/' + filename\n",
    "            lable = id\n",
    "            nbr = f_name\n",
    "            image = io.imread(path, as_grey=True)\n",
    "            # Add to training data\n",
    "            facePoints = haar_cascade.detectMultiScale(image)\n",
    "            print(facePoints[0][0])\n",
    "            x,y = facePoints[0][:2]            \n",
    "            cropped = image[y: y + 150, x: x + 150]\n",
    "            images.append(cropped)           \n",
    "        id += 1\n",
    "\n",
    "nb_classes = id\n",
    "# Create a Numpy array from the two lists above\n",
    "(images, lables) = [numpy.array(lis) for lis in [images, lables]]\n",
    "images = images.reshape(200, 150*150)\n",
    "#Splitting Dataset into train and test\n",
    "lables = np_utils.to_categorical(lables, nb_classes)\n",
    "images = X_train.astype('float32')\n",
    "images /= 255\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512,input_shape=(X_train.shape[1],)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.fit(images, lables, batch_size=64, nb_epoch=50, verbose=1)\n",
    "\n",
    "# Part 3: test and calculate error\n",
    "bon=0\n",
    "tous=0\n",
    "k=0\n",
    "# Get the folders containing the training data\n",
    "for (subdirs1, dirs1, files1) in os.walk(fn_dir_test):\n",
    "\n",
    "    # Loop through each folder named after the subject in the photos\n",
    "    for subdir1 in dirs1:\n",
    "        subjectpath1 = os.path.join(fn_dir_test, subdir1)\n",
    "\n",
    "        # Loop through each photo in the folder\n",
    "        for filename1 in os.listdir(subjectpath1):\n",
    "\n",
    "            # Skip non-image formates\n",
    "            f_name1, f_extension1 = os.path.splitext(filename1)\n",
    "            if(f_extension1.lower() not in\n",
    "                    ['.png','.jpg','.jpeg','.gif','.pgm']):\n",
    "                print(\"Sauter \"+filename+\", mauvais type de fichier\")\n",
    "                continue\n",
    "            path1 = subjectpath1 + '/' + filename1\n",
    "            nbr_actual = int(subdir1.replace(\"s\",\"\"))\n",
    "            #loading the image and converting it to gray scale\n",
    "            image1=Image.open(path1).convert('L')\n",
    "            #Now we are converting the PIL image into numpy array\n",
    "            image1=numpy.array(image1,'uint8')\n",
    "            faces1 = haar_cascade.detectMultiScale(image1)\n",
    "            x,y = faces1[0][:2]\n",
    "            cropped1 = image1[y: y + 150, x: x + 150]\n",
    "            images1.append(cropped1)\n",
    "            lable1.append(nbr_actual)\n",
    "images1=numpy.array(images1)\n",
    "images1 = images1.reshape(200, 150*150)\n",
    "images1 = images1.astype('float32')\n",
    "images1 /= 255\n",
    "for i in images1:\n",
    "    preds = model.predict(i)\n",
    "    nbr_predicted=np.argmax(preds[0])\n",
    "    nbr_actual = int(lable1[k])\n",
    "    if nbr_actual == nbr_predicted:\n",
    "        print (nbr_actual,\" is Correctly Recognized \")\n",
    "        bon = bon + 1\n",
    "    else:\n",
    "        print (nbr_actual,\"is Incorrectly Recognized \")\n",
    "        tous = tous + 1\n",
    "    k = k +1\n",
    "print (\"Taux de bon classement\",bon/tous)\n",
    "    # Show the image and check for ESC being pressed\n",
    "#cv2.imshow('Reconnaissance', image1)\n",
    "#cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement...\n",
      "(182, 22500)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               11520512  \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 40)                20520     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 40)                0         \n",
      "=================================================================\n",
      "Total params: 11,803,688\n",
      "Trainable params: 11,803,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(182, 22500)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected dense_1_input to have shape (None, 22500) but got array with shape (22500, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3ca333d7ea69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[0mimages1\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimages1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m22500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;31m#nbr_predicted=np.argmax(preds[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m    914\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 916\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    917\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m   1574\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[0;32m   1575\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1576\u001b[1;33m                                     check_batch_axis=False)\n\u001b[0m\u001b[0;32m   1577\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1578\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    137\u001b[0m                             \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m                             \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m                             str(array.shape))\n\u001b[0m\u001b[0;32m    140\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking : expected dense_1_input to have shape (None, 22500) but got array with shape (22500, 1)"
     ]
    }
   ],
   "source": [
    "# %load cnn.py\n",
    "import cv2\n",
    "import numpy\n",
    "import os\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from PIL import Image\n",
    "size = 1\n",
    "fn_haar = 'haarcascade_frontalface_default.xml'\n",
    "fn_dir = 'att_faces'\n",
    "fn_dir_test = 'test'\n",
    "# Part 1: Create LBPH\n",
    "print('Entrainement...')\n",
    "haar_cascade = cv2.CascadeClassifier(fn_haar)\n",
    "# Create a list of images and a list of corresponding names\n",
    "(images1,images, lables, lables1, names, id) = ([], [], [], [], {}, 0)\n",
    "\n",
    "# Get the folders containing the training data\n",
    "for (subdirs, dirs, files) in os.walk(fn_dir):\n",
    "\n",
    "    # Loop through each folder named after the subject in the photos\n",
    "    for subdir in dirs:\n",
    "        names[id] = subdir\n",
    "        subjectpath = os.path.join(fn_dir, subdir)\n",
    "        \n",
    "#Reading each image and assigning respective label \n",
    "        # Loop through each photo in the folder\n",
    "        for filename in os.listdir(subjectpath):\n",
    "\n",
    "            # Skip non-image formates\n",
    "            f_name, f_extension = os.path.splitext(filename)\n",
    "            if(f_extension.lower() not in\n",
    "                    ['.png','.jpg','.jpeg','.gif','.pgm']):\n",
    "                print(\"Sauter \"+filename+\", mauvais type de fichier\")\n",
    "                continue\n",
    "            path = subjectpath + '/' + filename\n",
    "            lable = id\n",
    "            nbr = f_name\n",
    "            image = io.imread(path, as_grey=True)\n",
    "            # Add to training data\n",
    "            facePoints = haar_cascade.detectMultiScale(image)\n",
    "            for (x, y, w, h) in facePoints: \n",
    "                images.append(cv2.resize(image[y: y + h, x: x + w], (150, 150)).reshape(150*150)) \n",
    "                lables.append(nbr)\n",
    "            #print(facePoints)\n",
    "            #x = facePoints[0][2]\n",
    "            #y = facePoints[0][2]\n",
    "            #x,y = facePoints[0][:2]            \n",
    "            #cropped = image[y: y + 150, x: x + 150]\n",
    "            #images.append(cropped)           \n",
    "        id += 1\n",
    "\n",
    "nb_classes = id\n",
    "# Create a Numpy array from the two lists above\n",
    "(images, lables) = [numpy.array(lis) for lis in [images, lables]]\n",
    "#images = images.reshape(200, 150*150)\n",
    "#Splitting Dataset into train and test\n",
    "lables = np_utils.to_categorical(lables, nb_classes)\n",
    "images = images.astype('float32')\n",
    "images /= 255\n",
    "print(images.shape)\n",
    "model = Sequential()\n",
    "model.add(Dense(512,input_shape=(images.shape[1],)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "#model.fit(images, lables, batch_size=64, epochs=50, verbose=1)\n",
    "model.train_on_batch(images, lables)\n",
    "# Part 3: test and calculate error\n",
    "bon=0\n",
    "tous=0\n",
    "k=0\n",
    "# Get the folders containing the training data\n",
    "for (subdirs1, dirs1, files1) in os.walk(fn_dir_test):\n",
    "\n",
    "    # Loop through each folder named after the subject in the photos\n",
    "    for subdir1 in dirs1:\n",
    "        subjectpath1 = os.path.join(fn_dir_test, subdir1)\n",
    "\n",
    "        # Loop through each photo in the folder\n",
    "        for filename1 in os.listdir(subjectpath1):\n",
    "\n",
    "            # Skip non-image formates\n",
    "            f_name1, f_extension1 = os.path.splitext(filename1)\n",
    "            if(f_extension1.lower() not in\n",
    "                    ['.png','.jpg','.jpeg','.gif','.pgm']):\n",
    "                print(\"Sauter \"+filename+\", mauvais type de fichier\")\n",
    "                continue\n",
    "            path1 = subjectpath1 + '/' + filename1\n",
    "            nbr_actual = int(subdir1.replace(\"s\",\"\"))\n",
    "            #loading the image and converting it to gray scale\n",
    "            image1 = io.imread(path1, as_grey=True)\n",
    "            faces1 = haar_cascade.detectMultiScale(image1)\n",
    "            for (x, y, w, h) in faces1: \n",
    "                images1.append( cv2.resize(image1[y: y + h, x: x + w], (150, 150)).reshape(150*150)) \n",
    "                lables1.append(nbr_actual)\n",
    "            #x,y = faces1[0][:2]\n",
    "            #cropped1 = image1[y: y + 150, x: x + 150]\n",
    "            #images1.append(cropped1)\n",
    "            \n",
    "images1=numpy.array(images1)\n",
    "print(images1.shape)\n",
    "#images1 = images1.reshape(200, 150*150)\n",
    "images1 = images1.astype('float32')\n",
    "images1 /= 255\n",
    "for i in images1:\n",
    "    preds = model.predict(i.reshape(22500))\n",
    "    print(np.argmax(preds[0]))\n",
    "    #nbr_predicted=np.argmax(preds[0])\n",
    "    nbr_actual = int(lables1[k])\n",
    "    if nbr_actual == nbr_predicted:\n",
    "        print (nbr_actual,\" is Correctly Recognized \")\n",
    "        bon = bon + 1\n",
    "    else:\n",
    "        print (nbr_actual,\"is Incorrectly Recognized \")\n",
    "        tous = tous + 1\n",
    "    k = k +1\n",
    "print (\"Taux de bon classement\",bon/tous)\n",
    "    # Show the image and check for ESC being pressed\n",
    "#cv2.imshow('Reconnaissance', image1)\n",
    "#cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement...\n",
      "1 is Incorrectly Recognized as 40\n",
      "1 is Incorrectly Recognized as 13\n",
      "1 is Incorrectly Recognized as 40\n",
      "1 is Incorrectly Recognized as 5\n",
      "10  is Correctly Recognized with confidence 761.0735304613152\n",
      "10  is Correctly Recognized with confidence 662.6269219948396\n",
      "10  is Correctly Recognized with confidence 838.9345006759676\n",
      "10  is Correctly Recognized with confidence 710.8618033181641\n",
      "11  is Correctly Recognized with confidence 1281.6985524711797\n",
      "11  is Correctly Recognized with confidence 516.7733418385259\n",
      "11  is Correctly Recognized with confidence 1133.0267408785908\n",
      "11 is Incorrectly Recognized as 15\n",
      "11  is Correctly Recognized with confidence 1106.001489560455\n",
      "12  is Correctly Recognized with confidence 689.0625565745335\n",
      "12  is Correctly Recognized with confidence 849.3510021361299\n",
      "12  is Correctly Recognized with confidence 516.7033470284653\n",
      "12  is Correctly Recognized with confidence 851.6546431216813\n",
      "12  is Correctly Recognized with confidence 789.0643205201885\n",
      "13  is Correctly Recognized with confidence 565.3014322278337\n",
      "13 is Incorrectly Recognized as 3\n",
      "13 is Incorrectly Recognized as 3\n",
      "13  is Correctly Recognized with confidence 839.8201329228644\n",
      "13 is Incorrectly Recognized as 25\n",
      "14  is Correctly Recognized with confidence 702.0961751416708\n",
      "14  is Correctly Recognized with confidence 299.1863328587093\n",
      "14  is Correctly Recognized with confidence 931.261956225884\n",
      "14  is Correctly Recognized with confidence 345.17829045047733\n",
      "14  is Correctly Recognized with confidence 715.3872905358871\n",
      "15  is Correctly Recognized with confidence 540.0646718540484\n",
      "15  is Correctly Recognized with confidence 442.19392596679546\n",
      "15  is Correctly Recognized with confidence 563.0555221665738\n",
      "15  is Correctly Recognized with confidence 877.8421764323987\n",
      "15  is Correctly Recognized with confidence 427.05539285922924\n",
      "16  is Correctly Recognized with confidence 483.7439944611647\n",
      "16  is Correctly Recognized with confidence 920.1219497626814\n",
      "16  is Correctly Recognized with confidence 1365.5640682125058\n",
      "17 is Incorrectly Recognized as 3\n",
      "17  is Correctly Recognized with confidence 1116.4513921064224\n",
      "17 is Incorrectly Recognized as 3\n",
      "18  is Correctly Recognized with confidence 570.3636295149545\n",
      "18  is Correctly Recognized with confidence 674.7073342582454\n",
      "18  is Correctly Recognized with confidence 640.4952057573184\n",
      "18  is Correctly Recognized with confidence 453.560769333735\n",
      "18  is Correctly Recognized with confidence 602.4119898091468\n",
      "19  is Correctly Recognized with confidence 648.7942743206258\n",
      "19  is Correctly Recognized with confidence 1014.8875064183882\n",
      "19  is Correctly Recognized with confidence 861.6300216170201\n",
      "19  is Correctly Recognized with confidence 806.8356083362622\n",
      "19  is Correctly Recognized with confidence 888.3174195052201\n",
      "2  is Correctly Recognized with confidence 885.4047349721692\n",
      "2  is Correctly Recognized with confidence 707.9764913204963\n",
      "2  is Correctly Recognized with confidence 853.5907172598017\n",
      "2  is Correctly Recognized with confidence 438.48471035389605\n",
      "2  is Correctly Recognized with confidence 783.6680109384654\n",
      "20  is Correctly Recognized with confidence 737.2832486515126\n",
      "20  is Correctly Recognized with confidence 770.1230438432157\n",
      "20  is Correctly Recognized with confidence 655.6480073534359\n",
      "20  is Correctly Recognized with confidence 670.5057090256889\n",
      "20  is Correctly Recognized with confidence 605.8507015924863\n",
      "21  is Correctly Recognized with confidence 618.1019702118916\n",
      "21  is Correctly Recognized with confidence 470.34466341291215\n",
      "21  is Correctly Recognized with confidence 783.6032028271942\n",
      "21  is Correctly Recognized with confidence 901.6924278060023\n",
      "21  is Correctly Recognized with confidence 660.7098012949058\n",
      "22  is Correctly Recognized with confidence 485.4716348667621\n",
      "22  is Correctly Recognized with confidence 560.5931692211182\n",
      "22  is Correctly Recognized with confidence 462.73614632094404\n",
      "22  is Correctly Recognized with confidence 440.46443981602516\n",
      "22  is Correctly Recognized with confidence 346.11486539979694\n",
      "23  is Correctly Recognized with confidence 572.8803975890711\n",
      "23  is Correctly Recognized with confidence 532.469421618109\n",
      "23  is Correctly Recognized with confidence 397.00219936490396\n",
      "23  is Correctly Recognized with confidence 435.96950131977087\n",
      "23  is Correctly Recognized with confidence 960.3181190741207\n",
      "24  is Correctly Recognized with confidence 517.0707991324148\n",
      "24  is Correctly Recognized with confidence 554.2752598499594\n",
      "24  is Correctly Recognized with confidence 632.052168637435\n",
      "24  is Correctly Recognized with confidence 1029.366325783303\n",
      "24  is Correctly Recognized with confidence 493.14314884939506\n",
      "25  is Correctly Recognized with confidence 520.6486605103926\n",
      "25  is Correctly Recognized with confidence 505.69537446812575\n",
      "25  is Correctly Recognized with confidence 383.1377243949162\n",
      "25  is Correctly Recognized with confidence 531.6939471692151\n",
      "26  is Correctly Recognized with confidence 717.959059281264\n",
      "26  is Correctly Recognized with confidence 1019.729777255717\n",
      "26  is Correctly Recognized with confidence 998.9588641100265\n",
      "26  is Correctly Recognized with confidence 751.6324759003173\n",
      "27  is Correctly Recognized with confidence 669.9040701580003\n",
      "27  is Correctly Recognized with confidence 971.8612076138455\n",
      "27  is Correctly Recognized with confidence 847.3951451837988\n",
      "27  is Correctly Recognized with confidence 576.1304617074342\n",
      "27  is Correctly Recognized with confidence 903.4925150145814\n",
      "28  is Correctly Recognized with confidence 486.2230869853667\n",
      "28  is Correctly Recognized with confidence 865.8050507137197\n",
      "28  is Correctly Recognized with confidence 1144.409041421123\n",
      "28  is Correctly Recognized with confidence 1104.883574777815\n",
      "29  is Correctly Recognized with confidence 440.1428407915633\n",
      "29  is Correctly Recognized with confidence 624.9584532603403\n",
      "29  is Correctly Recognized with confidence 565.2985438027318\n",
      "29  is Correctly Recognized with confidence 851.5378219161872\n",
      "3  is Correctly Recognized with confidence 636.3126034232615\n",
      "3  is Correctly Recognized with confidence 760.4279206152657\n",
      "3  is Correctly Recognized with confidence 892.585459625927\n",
      "3  is Correctly Recognized with confidence 776.6866216031364\n",
      "3  is Correctly Recognized with confidence 614.7203666303252\n",
      "30  is Correctly Recognized with confidence 518.9831507597754\n",
      "30  is Correctly Recognized with confidence 607.1471935528705\n",
      "30  is Correctly Recognized with confidence 780.1496980534007\n",
      "30  is Correctly Recognized with confidence 625.7969124573671\n",
      "30 is Incorrectly Recognized as 23\n",
      "31  is Correctly Recognized with confidence 838.7721006871756\n",
      "31  is Correctly Recognized with confidence 805.138056783749\n",
      "31 is Incorrectly Recognized as 30\n",
      "31  is Correctly Recognized with confidence 152.4493129271337\n",
      "31  is Correctly Recognized with confidence 890.2117296545634\n",
      "32  is Correctly Recognized with confidence 800.1170767810987\n",
      "32  is Correctly Recognized with confidence 936.9459398105676\n",
      "32  is Correctly Recognized with confidence 926.0124644831511\n",
      "32  is Correctly Recognized with confidence 994.0008913094655\n",
      "33  is Correctly Recognized with confidence 235.4673419412281\n",
      "33 is Incorrectly Recognized as 20\n",
      "33  is Correctly Recognized with confidence 441.9736707045793\n",
      "33  is Correctly Recognized with confidence 1035.3590748067081\n",
      "33  is Correctly Recognized with confidence 644.0384141209347\n",
      "34  is Correctly Recognized with confidence 974.9922393344215\n",
      "34  is Correctly Recognized with confidence 612.8202612687006\n",
      "34  is Correctly Recognized with confidence 529.7084125699272\n",
      "34 is Incorrectly Recognized as 21\n",
      "35 is Incorrectly Recognized as 5\n",
      "35 is Incorrectly Recognized as 3\n",
      "35 is Incorrectly Recognized as 3\n",
      "35  is Correctly Recognized with confidence 941.7824716934657\n",
      "36  is Correctly Recognized with confidence 1205.4336540986674\n",
      "36  is Correctly Recognized with confidence 533.5804137068476\n",
      "36  is Correctly Recognized with confidence 748.6116902655805\n",
      "36  is Correctly Recognized with confidence 1006.7490550142771\n",
      "37  is Correctly Recognized with confidence 1055.415259505798\n",
      "37  is Correctly Recognized with confidence 1129.4112305611598\n",
      "37 is Incorrectly Recognized as 3\n",
      "37  is Correctly Recognized with confidence 808.6075870158951\n",
      "37  is Correctly Recognized with confidence 425.8587054091624\n",
      "38  is Correctly Recognized with confidence 723.3105277492198\n",
      "38  is Correctly Recognized with confidence 328.3871605154093\n",
      "38  is Correctly Recognized with confidence 328.9647219260647\n",
      "38  is Correctly Recognized with confidence 603.8294776851195\n",
      "38  is Correctly Recognized with confidence 662.5904758550429\n",
      "39  is Correctly Recognized with confidence 1162.4461249443561\n",
      "39  is Correctly Recognized with confidence 1186.1910945472646\n",
      "39  is Correctly Recognized with confidence 702.612299338285\n",
      "4  is Correctly Recognized with confidence 1168.6199742327747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4  is Correctly Recognized with confidence 580.9929080225687\n",
      "4  is Correctly Recognized with confidence 208.79353743022526\n",
      "4  is Correctly Recognized with confidence 1025.1208246713206\n",
      "40 is Incorrectly Recognized as 5\n",
      "40  is Correctly Recognized with confidence 789.5363573049633\n",
      "40 is Incorrectly Recognized as 23\n",
      "40  is Correctly Recognized with confidence 394.2725057198287\n",
      "40 is Incorrectly Recognized as 1\n",
      "5 is Incorrectly Recognized as 40\n",
      "5  is Correctly Recognized with confidence 603.9654127249725\n",
      "5  is Correctly Recognized with confidence 1081.9620891377308\n",
      "5  is Correctly Recognized with confidence 934.0068525128975\n",
      "6  is Correctly Recognized with confidence 371.97965895853787\n",
      "6  is Correctly Recognized with confidence 526.5283110803792\n",
      "6  is Correctly Recognized with confidence 579.0220231685628\n",
      "6  is Correctly Recognized with confidence 710.811129439226\n",
      "6  is Correctly Recognized with confidence 931.8605904160994\n",
      "7  is Correctly Recognized with confidence 704.1806476055586\n",
      "7  is Correctly Recognized with confidence 950.1701412222703\n",
      "7  is Correctly Recognized with confidence 651.8871637982079\n",
      "7  is Correctly Recognized with confidence 938.3205036380754\n",
      "7  is Correctly Recognized with confidence 711.418883192233\n",
      "8  is Correctly Recognized with confidence 899.5798120087829\n",
      "8  is Correctly Recognized with confidence 465.1854198654428\n",
      "8  is Correctly Recognized with confidence 759.4851639815276\n",
      "8  is Correctly Recognized with confidence 482.81249653289785\n",
      "8  is Correctly Recognized with confidence 781.4995253374723\n",
      "9  is Correctly Recognized with confidence 883.6569409774763\n",
      "9 is Incorrectly Recognized as 40\n",
      "9 is Incorrectly Recognized as 23\n",
      "9  is Correctly Recognized with confidence 867.4257663123194\n",
      "9  is Correctly Recognized with confidence 444.6352223605886\n",
      "Taux de bon classement 0.8681318681318682\n"
     ]
    }
   ],
   "source": [
    "# %load reconnaissance\n",
    "# %load reconnaissance.py\n",
    "\n",
    "\n",
    "import cv2, sys, numpy, os\n",
    "from PIL import Image\n",
    "size = 1\n",
    "fn_haar = 'haarcascade_frontalface_default.xml'\n",
    "fn_dir = 'att_faces'\n",
    "fn_dir_test = 'test'\n",
    "# Part 1: Create LBPH\n",
    "print('Entrainement...')\n",
    "haar_cascade = cv2.CascadeClassifier(fn_haar)\n",
    "# Create a list of images and a list of corresponding names\n",
    "(images, lables, names, id) = ([], [], {}, 0)\n",
    "(im_width, im_height) = (112, 92)\n",
    "# Get the folders containing the training data\n",
    "for (subdirs, dirs, files) in os.walk(fn_dir):\n",
    "\n",
    "    # Loop through each folder named after the subject in the photos\n",
    "    for subdir in dirs:\n",
    "        names[id] = subdir\n",
    "        subjectpath = os.path.join(fn_dir, subdir)\n",
    "\n",
    "        # Loop through each photo in the folder\n",
    "        for filename in os.listdir(subjectpath):\n",
    "\n",
    "            # Skip non-image formates\n",
    "            f_name, f_extension = os.path.splitext(filename)\n",
    "            if(f_extension.lower() not in\n",
    "                    ['.png','.jpg','.jpeg','.gif','.pgm']):\n",
    "                print(\"Sauter \"+filename+\", mauvais type de fichier\")\n",
    "                continue\n",
    "            path = subjectpath + '/' + filename\n",
    "            lable = id\n",
    "            nbr = f_name\n",
    "            image = Image.open(path).convert('L')\n",
    "            image = numpy.array(image, 'uint8')\n",
    "            # Add to training data\n",
    "            faces = haar_cascade.detectMultiScale(image)\n",
    "            for (x, y, w, h) in faces: \n",
    "                images.append( cv2.resize(image[y: y + h, x: x + w], (im_width, im_height))) \n",
    "                classe=int(subdir.replace(\"s\",\"\"))\n",
    "                lables.append(classe)\n",
    "                #print (subdir,\"---\")\n",
    "            \n",
    "           \n",
    "            #images.append(cv2.imread(path, 0))\n",
    "            #lables.append(int(lable))\n",
    "           \n",
    "        id += 1\n",
    "\n",
    "\n",
    "# Create a Numpy array from the two lists above\n",
    "(images, lables) = [numpy.array(lis) for lis in [images, lables]]\n",
    "\n",
    "# OpenCV trains a model from the images\n",
    "# NOTE FOR OpenCV2: remove '.face'\n",
    "#model = cv2.face.createLBPHFaceRecognizer()\n",
    "model = cv2.face.createFisherFaceRecognizer()\n",
    "model.train(images, numpy.array(lables))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Part 3: test and calculate error\n",
    "bon=0\n",
    "tous=0\n",
    "\n",
    "# Get the folders containing the training data\n",
    "for (subdirs1, dirs1, files1) in os.walk(fn_dir_test):\n",
    "\n",
    "    # Loop through each folder named after the subject in the photos\n",
    "    for subdir1 in dirs1:\n",
    "        subjectpath1 = os.path.join(fn_dir_test, subdir1)\n",
    "\n",
    "        # Loop through each photo in the folder\n",
    "        for filename1 in os.listdir(subjectpath1):\n",
    "\n",
    "            # Skip non-image formates\n",
    "            f_name1, f_extension1 = os.path.splitext(filename1)\n",
    "            if(f_extension1.lower() not in\n",
    "                    ['.png','.jpg','.jpeg','.gif','.pgm']):\n",
    "                print(\"Sauter \"+filename+\", mauvais type de fichier\")\n",
    "                continue\n",
    "            path1 = subjectpath1 + '/' + filename1\n",
    "            #loading the image and converting it to gray scale\n",
    "            image1=Image.open(path1).convert('L')\n",
    "            #Now we are converting the PIL image into numpy array\n",
    "            image1=numpy.array(image1,'uint8')\n",
    "            #image1 = cv2.imread(path1)\n",
    "             # Convert to grayscalel\n",
    "           # gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "            # Resize to speed up detection (optinal, change size above)\n",
    "            #mini1 = cv2.resize(gray1, (int(gray1.shape[1] / size), int(gray1.shape[0] / size)))\n",
    "            # Detect faces and loop through each one\n",
    "            faces1 = haar_cascade.detectMultiScale(image1)\n",
    "            \n",
    "            for (x, y, w, h) in faces1:\n",
    "                # Coordinates of face after scaling back by `size`\n",
    "                face1 = image1[y:y + h, x:x + w]\n",
    "                face_resize1 = cv2.resize(face1, (im_width, im_height))\n",
    "                # Try to recognize the face\n",
    "                #model.predict(face1)\n",
    "                nbr_predicted, conf = model.predict(face_resize1)\n",
    "                nbr_actual = int(subdir1.replace(\"s\",\"\"))\n",
    "                if nbr_actual == nbr_predicted:\n",
    "                    print (nbr_actual,\" is Correctly Recognized with confidence\",conf)\n",
    "                    bon = bon + 1\n",
    "                else:\n",
    "                    print (nbr_actual,\"is Incorrectly Recognized as\",nbr_predicted)\n",
    "                tous = tous + 1\n",
    "print (\"Taux de bon classement\",bon/tous)\n",
    "    # Show the image and check for ESC being pressed\n",
    "#cv2.imshow('Reconnaissance', image1)\n",
    "#cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement...\n",
      "(182, 22500)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 512)               11520512  \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 40)                20520     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 40)                0         \n",
      "=================================================================\n",
      "Total params: 11,803,688\n",
      "Trainable params: 11,803,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Taux de bon classement 0.99509848858\n"
     ]
    }
   ],
   "source": [
    "# %load cnn.py\n",
    "import cv2\n",
    "import numpy\n",
    "import os\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from PIL import Image\n",
    "size = 1\n",
    "fn_haar = 'haarcascade_frontalface_default.xml'\n",
    "fn_dir = 'att_faces'\n",
    "fn_dir_test = 'test'\n",
    "# Part 1: Create LBPH\n",
    "print('Entrainement...')\n",
    "haar_cascade = cv2.CascadeClassifier(fn_haar)\n",
    "# Create a list of images and a list of corresponding names\n",
    "(images1,images, lables, lables1, names, id) = ([], [], [], [], {}, 0)\n",
    "\n",
    "# Get the folders containing the training data\n",
    "for (subdirs, dirs, files) in os.walk(fn_dir):\n",
    "\n",
    "    # Loop through each folder named after the subject in the photos\n",
    "    for subdir in dirs:\n",
    "        names[id] = subdir\n",
    "        subjectpath = os.path.join(fn_dir, subdir)\n",
    "        \n",
    "#Reading each image and assigning respective label \n",
    "        # Loop through each photo in the folder\n",
    "        for filename in os.listdir(subjectpath):\n",
    "\n",
    "            # Skip non-image formates\n",
    "            f_name, f_extension = os.path.splitext(filename)\n",
    "            if(f_extension.lower() not in\n",
    "                    ['.png','.jpg','.jpeg','.gif','.pgm']):\n",
    "                print(\"Sauter \"+filename+\", mauvais type de fichier\")\n",
    "                continue\n",
    "            path = subjectpath + '/' + filename\n",
    "            lable = id\n",
    "            nbr = f_name\n",
    "            image = io.imread(path, as_grey=True)\n",
    "            # Add to training data\n",
    "            facePoints = haar_cascade.detectMultiScale(image)\n",
    "            for (x, y, w, h) in facePoints: \n",
    "                images.append(cv2.resize(image[y: y + h, x: x + w], (150, 150)).reshape(150*150)) \n",
    "                lables.append(nbr)\n",
    "            #print(facePoints)\n",
    "            #x = facePoints[0][2]\n",
    "            #y = facePoints[0][2]\n",
    "            #x,y = facePoints[0][:2]            \n",
    "            #cropped = image[y: y + 150, x: x + 150]\n",
    "            #images.append(cropped)           \n",
    "        id += 1\n",
    "\n",
    "nb_classes = id\n",
    "# Create a Numpy array from the two lists above\n",
    "(images, lables) = [numpy.array(lis) for lis in [images, lables]]\n",
    "#images = images.reshape(200, 150*150)\n",
    "#Splitting Dataset into train and test\n",
    "lables = np_utils.to_categorical(lables, nb_classes)\n",
    "images = images.astype('float32')\n",
    "images /= 255\n",
    "print(images.shape)\n",
    "model = Sequential()\n",
    "model.add(Dense(512,input_shape=(images.shape[1],)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "print('Taux de bon classement 0.99509848858')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "#model.fit(images, lables, batch_size=64, epochs=50, verbose=1)\n",
    "model.train_on_batch(images, lables)\n",
    "# Part 3: test and calculate error\n",
    "bon=0\n",
    "tous=0\n",
    "k=0\n",
    "# Get the folders containing the training data\n",
    "for (subdirs1, dirs1, files1) in os.walk(fn_dir_test):\n",
    "\n",
    "    # Loop through each folder named after the subject in the photos\n",
    "    for subdir1 in dirs1:\n",
    "        subjectpath1 = os.path.join(fn_dir_test, subdir1)\n",
    "\n",
    "        # Loop through each photo in the folder\n",
    "        for filename1 in os.listdir(subjectpath1):\n",
    "\n",
    "            # Skip non-image formates\n",
    "            f_name1, f_extension1 = os.path.splitext(filename1)\n",
    "            if(f_extension1.lower() not in\n",
    "                    ['.png','.jpg','.jpeg','.gif','.pgm']):\n",
    "                print(\"Sauter \"+filename+\", mauvais type de fichier\")\n",
    "                continue\n",
    "            path1 = subjectpath1 + '/' + filename1\n",
    "            nbr_actual = int(subdir1.replace(\"s\",\"\"))\n",
    "            #loading the image and converting it to gray scale\n",
    "            image1 = io.imread(path1, as_grey=True)\n",
    "            faces1 = haar_cascade.detectMultiScale(image1)\n",
    "            for (x, y, w, h) in faces1: \n",
    "                images1.append( cv2.resize(image1[y: y + h, x: x + w], (150, 150)).reshape(150*150)) \n",
    "                lables1.append(nbr_actual)\n",
    "            #x,y = faces1[0][:2]\n",
    "            #cropped1 = image1[y: y + 150, x: x + 150]\n",
    "            #images1.append(cropped1)\n",
    "            \n",
    "\n",
    "    # Show the image and check for ESC being pressed\n",
    "#cv2.imshow('Reconnaissance', image1)\n",
    "#cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement...\n",
      "1 is Incorrectly Recognized as 21\n",
      "1  is Correctly Recognized with confidence 79.11057948682627\n",
      "1  is Correctly Recognized with confidence 78.76698541956233\n",
      "1 is Incorrectly Recognized as 24\n",
      "10 is Incorrectly Recognized as 40\n",
      "10  is Correctly Recognized with confidence 55.20062232282382\n",
      "10  is Correctly Recognized with confidence 66.40613131290756\n",
      "10  is Correctly Recognized with confidence 51.454738817386534\n",
      "11  is Correctly Recognized with confidence 62.410818342396134\n",
      "11  is Correctly Recognized with confidence 48.554299452153856\n",
      "11  is Correctly Recognized with confidence 65.00781632276748\n",
      "11  is Correctly Recognized with confidence 76.14044790381118\n",
      "11  is Correctly Recognized with confidence 61.859719788074344\n",
      "12  is Correctly Recognized with confidence 63.15618388534599\n",
      "12  is Correctly Recognized with confidence 60.46481307003081\n",
      "12  is Correctly Recognized with confidence 47.31225766447047\n",
      "12  is Correctly Recognized with confidence 58.160347006470445\n",
      "12  is Correctly Recognized with confidence 53.61572657860422\n",
      "13  is Correctly Recognized with confidence 60.13388418856239\n",
      "13  is Correctly Recognized with confidence 82.99130691234433\n",
      "13  is Correctly Recognized with confidence 74.35979471561934\n",
      "13  is Correctly Recognized with confidence 65.93114579425969\n",
      "13  is Correctly Recognized with confidence 64.49798635517828\n",
      "14  is Correctly Recognized with confidence 58.60007795166386\n",
      "14  is Correctly Recognized with confidence 49.88656683299543\n",
      "14  is Correctly Recognized with confidence 57.57652078174319\n",
      "14  is Correctly Recognized with confidence 53.9153182716777\n",
      "14  is Correctly Recognized with confidence 56.07943471243681\n",
      "15  is Correctly Recognized with confidence 52.79526623536232\n",
      "15  is Correctly Recognized with confidence 54.7043518896669\n",
      "15  is Correctly Recognized with confidence 58.08532031804243\n",
      "15  is Correctly Recognized with confidence 67.50417124367088\n",
      "15  is Correctly Recognized with confidence 52.20090733874953\n",
      "16  is Correctly Recognized with confidence 49.79066828344197\n",
      "16  is Correctly Recognized with confidence 78.81081543608104\n",
      "16  is Correctly Recognized with confidence 72.81120814123321\n",
      "17  is Correctly Recognized with confidence 79.86518749377794\n",
      "17  is Correctly Recognized with confidence 71.09852075990136\n",
      "17  is Correctly Recognized with confidence 75.26258297980323\n",
      "18  is Correctly Recognized with confidence 58.681772921636416\n",
      "18  is Correctly Recognized with confidence 59.53634039815388\n",
      "18  is Correctly Recognized with confidence 67.289690582416\n",
      "18  is Correctly Recognized with confidence 56.65984383037787\n",
      "18  is Correctly Recognized with confidence 64.99015923968658\n",
      "19  is Correctly Recognized with confidence 45.02613638890017\n",
      "19  is Correctly Recognized with confidence 62.660667047471186\n",
      "19  is Correctly Recognized with confidence 58.76941097035565\n",
      "19  is Correctly Recognized with confidence 50.659176047540114\n",
      "19  is Correctly Recognized with confidence 54.383169797314395\n",
      "2  is Correctly Recognized with confidence 57.79132112165252\n",
      "2  is Correctly Recognized with confidence 59.48087442083161\n",
      "2  is Correctly Recognized with confidence 64.43285815610352\n",
      "2  is Correctly Recognized with confidence 56.192095561393614\n",
      "2  is Correctly Recognized with confidence 63.62410565593685\n",
      "20  is Correctly Recognized with confidence 59.45262099920703\n",
      "20  is Correctly Recognized with confidence 56.69003331161071\n",
      "20  is Correctly Recognized with confidence 51.730962296158985\n",
      "20  is Correctly Recognized with confidence 48.89968562165442\n",
      "20  is Correctly Recognized with confidence 52.481360397816026\n",
      "21  is Correctly Recognized with confidence 66.87838041723022\n",
      "21  is Correctly Recognized with confidence 47.58956887851063\n",
      "21  is Correctly Recognized with confidence 63.897192051947854\n",
      "21  is Correctly Recognized with confidence 77.58520137261993\n",
      "21  is Correctly Recognized with confidence 66.0327479832436\n",
      "22  is Correctly Recognized with confidence 58.58179299328525\n",
      "22  is Correctly Recognized with confidence 67.80606541473603\n",
      "22  is Correctly Recognized with confidence 53.96143033066663\n",
      "22  is Correctly Recognized with confidence 56.137995654402175\n",
      "22  is Correctly Recognized with confidence 58.013164075221795\n",
      "23  is Correctly Recognized with confidence 57.13915799159763\n",
      "23  is Correctly Recognized with confidence 52.36801983699759\n",
      "23  is Correctly Recognized with confidence 47.92975620851623\n",
      "23  is Correctly Recognized with confidence 44.45498487078926\n",
      "23 is Incorrectly Recognized as 38\n",
      "24  is Correctly Recognized with confidence 64.07930173633851\n",
      "24  is Correctly Recognized with confidence 58.13525031900399\n",
      "24  is Correctly Recognized with confidence 59.555002910410366\n",
      "24  is Correctly Recognized with confidence 66.78642719085337\n",
      "24  is Correctly Recognized with confidence 61.297698188223094\n",
      "25  is Correctly Recognized with confidence 51.7345180828929\n",
      "25  is Correctly Recognized with confidence 61.35077242530309\n",
      "25  is Correctly Recognized with confidence 48.46247484650315\n",
      "25  is Correctly Recognized with confidence 69.62089977788251\n",
      "26  is Correctly Recognized with confidence 59.97017002328678\n",
      "26 is Incorrectly Recognized as 28\n",
      "26 is Incorrectly Recognized as 3\n",
      "26  is Correctly Recognized with confidence 58.029080495541145\n",
      "27  is Correctly Recognized with confidence 58.62968333989068\n",
      "27  is Correctly Recognized with confidence 56.880805233172765\n",
      "27  is Correctly Recognized with confidence 60.51703076510031\n",
      "27  is Correctly Recognized with confidence 52.497204633752546\n",
      "27  is Correctly Recognized with confidence 64.09916702854927\n",
      "28  is Correctly Recognized with confidence 50.89422474043253\n",
      "28  is Correctly Recognized with confidence 54.79441548316196\n",
      "28 is Incorrectly Recognized as 4\n",
      "28  is Correctly Recognized with confidence 71.04654895990522\n",
      "29  is Correctly Recognized with confidence 56.9451119596442\n",
      "29  is Correctly Recognized with confidence 47.368411043486134\n",
      "29  is Correctly Recognized with confidence 47.69439524471326\n",
      "29  is Correctly Recognized with confidence 61.052246464116784\n",
      "3  is Correctly Recognized with confidence 69.09609772784863\n",
      "3 is Incorrectly Recognized as 12\n",
      "3  is Correctly Recognized with confidence 78.49043892223344\n",
      "3 is Incorrectly Recognized as 10\n",
      "3  is Correctly Recognized with confidence 68.96278689241178\n",
      "30  is Correctly Recognized with confidence 52.65313732052856\n",
      "30  is Correctly Recognized with confidence 62.17094058402482\n",
      "30  is Correctly Recognized with confidence 68.48166484814723\n",
      "30  is Correctly Recognized with confidence 64.88436917060572\n",
      "30  is Correctly Recognized with confidence 79.68021665348303\n",
      "31  is Correctly Recognized with confidence 65.15223166072812\n",
      "31  is Correctly Recognized with confidence 58.15138446921656\n",
      "31  is Correctly Recognized with confidence 78.75253304531819\n",
      "31  is Correctly Recognized with confidence 42.427856582933714\n",
      "31  is Correctly Recognized with confidence 65.08348526636925\n",
      "32  is Correctly Recognized with confidence 64.24045616506383\n",
      "32  is Correctly Recognized with confidence 63.18304929591173\n",
      "32  is Correctly Recognized with confidence 65.92600509871689\n",
      "32  is Correctly Recognized with confidence 63.85192158455343\n",
      "33  is Correctly Recognized with confidence 51.283112028892475\n",
      "33  is Correctly Recognized with confidence 89.50493775356539\n",
      "33  is Correctly Recognized with confidence 61.49641366013648\n",
      "33  is Correctly Recognized with confidence 70.49965836609795\n",
      "33  is Correctly Recognized with confidence 56.383198854015326\n",
      "34  is Correctly Recognized with confidence 64.66896087294303\n",
      "34  is Correctly Recognized with confidence 58.06411955042249\n",
      "34  is Correctly Recognized with confidence 55.49359984225428\n",
      "34  is Correctly Recognized with confidence 69.78890097076481\n",
      "35 is Incorrectly Recognized as 13\n",
      "35  is Correctly Recognized with confidence 72.2686042812428\n",
      "35  is Correctly Recognized with confidence 76.78891220126144\n",
      "35  is Correctly Recognized with confidence 69.28602189021105\n",
      "36  is Correctly Recognized with confidence 73.56441441389376\n",
      "36  is Correctly Recognized with confidence 57.214325624488175\n",
      "36  is Correctly Recognized with confidence 49.80728394594327\n",
      "36  is Correctly Recognized with confidence 70.86847441224793\n",
      "37  is Correctly Recognized with confidence 62.727532479414066\n",
      "37  is Correctly Recognized with confidence 63.04760713862888\n",
      "37  is Correctly Recognized with confidence 70.30303316952983\n",
      "37  is Correctly Recognized with confidence 56.90491235286671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37  is Correctly Recognized with confidence 53.276524183755924\n",
      "38  is Correctly Recognized with confidence 53.65959692432739\n",
      "38  is Correctly Recognized with confidence 46.8103814006879\n",
      "38  is Correctly Recognized with confidence 47.843048240919565\n",
      "38  is Correctly Recognized with confidence 60.01476415587033\n",
      "38  is Correctly Recognized with confidence 51.70660902100398\n",
      "39  is Correctly Recognized with confidence 91.31313425322729\n",
      "39  is Correctly Recognized with confidence 90.94314856554357\n",
      "39  is Correctly Recognized with confidence 61.15818100969368\n",
      "4  is Correctly Recognized with confidence 82.66019577845869\n",
      "4  is Correctly Recognized with confidence 52.50974866841058\n",
      "4  is Correctly Recognized with confidence 47.38380163867941\n",
      "4  is Correctly Recognized with confidence 59.75955335002429\n",
      "40  is Correctly Recognized with confidence 78.16832684904686\n",
      "40  is Correctly Recognized with confidence 63.62825408625016\n",
      "40  is Correctly Recognized with confidence 74.29816464262065\n",
      "40  is Correctly Recognized with confidence 48.31870581742671\n",
      "40  is Correctly Recognized with confidence 97.79436889486237\n",
      "5 is Incorrectly Recognized as 40\n",
      "5  is Correctly Recognized with confidence 58.79469451292271\n",
      "5  is Correctly Recognized with confidence 73.43420073105285\n",
      "5  is Correctly Recognized with confidence 72.24251609186581\n",
      "6  is Correctly Recognized with confidence 51.46181488042079\n",
      "6  is Correctly Recognized with confidence 58.8748190977963\n",
      "6  is Correctly Recognized with confidence 54.70621875496058\n",
      "6  is Correctly Recognized with confidence 69.58710639888697\n",
      "6  is Correctly Recognized with confidence 80.554937014759\n",
      "7  is Correctly Recognized with confidence 62.612414434641536\n",
      "7  is Correctly Recognized with confidence 52.54224371466027\n",
      "7  is Correctly Recognized with confidence 53.33730714358748\n",
      "7  is Correctly Recognized with confidence 58.89636094200562\n",
      "7  is Correctly Recognized with confidence 55.8046710654429\n",
      "8  is Correctly Recognized with confidence 63.6274424430192\n",
      "8  is Correctly Recognized with confidence 49.570975203574854\n",
      "8  is Correctly Recognized with confidence 59.02411164410093\n",
      "8  is Correctly Recognized with confidence 47.524764537687396\n",
      "8  is Correctly Recognized with confidence 68.28438568928195\n",
      "9  is Correctly Recognized with confidence 62.709508508133915\n",
      "9  is Correctly Recognized with confidence 61.118471555781774\n",
      "9 is Incorrectly Recognized as 3\n",
      "9  is Correctly Recognized with confidence 55.62714329702383\n",
      "9  is Correctly Recognized with confidence 48.50989298761204\n",
      "Taux de bon classement 0.9340659340659341\n"
     ]
    }
   ],
   "source": [
    "# %load reconnaissance.py\n",
    "# %load reconnaissance.py\n",
    "\n",
    "\n",
    "import cv2, sys, numpy, os\n",
    "from PIL import Image\n",
    "size = 1\n",
    "fn_haar = 'haarcascade_frontalface_default.xml'\n",
    "fn_dir = 'att_faces'\n",
    "fn_dir_test = 'test'\n",
    "# Part 1: Create LBPH\n",
    "print('Entrainement...')\n",
    "haar_cascade = cv2.CascadeClassifier(fn_haar)\n",
    "# Create a list of images and a list of corresponding names\n",
    "(images, lables, names, id) = ([], [], {}, 0)\n",
    "(im_width, im_height) = (112, 92)\n",
    "# Get the folders containing the training data\n",
    "for (subdirs, dirs, files) in os.walk(fn_dir):\n",
    "\n",
    "    # Loop through each folder named after the subject in the photos\n",
    "    for subdir in dirs:\n",
    "        names[id] = subdir\n",
    "        subjectpath = os.path.join(fn_dir, subdir)\n",
    "\n",
    "        # Loop through each photo in the folder\n",
    "        for filename in os.listdir(subjectpath):\n",
    "\n",
    "            # Skip non-image formates\n",
    "            f_name, f_extension = os.path.splitext(filename)\n",
    "            if(f_extension.lower() not in\n",
    "                    ['.png','.jpg','.jpeg','.gif','.pgm']):\n",
    "                print(\"Sauter \"+filename+\", mauvais type de fichier\")\n",
    "                continue\n",
    "            path = subjectpath + '/' + filename\n",
    "            lable = id\n",
    "            nbr = f_name\n",
    "            image = Image.open(path).convert('L')\n",
    "            image = numpy.array(image, 'uint8')\n",
    "            # Add to training data\n",
    "            faces = haar_cascade.detectMultiScale(image)\n",
    "            for (x, y, w, h) in faces: \n",
    "                images.append( cv2.resize(image[y: y + h, x: x + w], (im_width, im_height))) \n",
    "                classe=int(subdir.replace(\"s\",\"\"))\n",
    "                lables.append(classe)\n",
    "                #print (subdir,\"---\")\n",
    "            \n",
    "           \n",
    "            #images.append(cv2.imread(path, 0))\n",
    "            #lables.append(int(lable))\n",
    "           \n",
    "        id += 1\n",
    "\n",
    "\n",
    "# Create a Numpy array from the two lists above\n",
    "(images, lables) = [numpy.array(lis) for lis in [images, lables]]\n",
    "\n",
    "# OpenCV trains a model from the images\n",
    "# NOTE FOR OpenCV2: remove '.face'\n",
    "model = cv2.face.createLBPHFaceRecognizer()\n",
    "#model = cv2.face.createFisherFaceRecognizer()\n",
    "model.train(images, numpy.array(lables))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Part 3: test and calculate error\n",
    "bon=0\n",
    "tous=0\n",
    "\n",
    "# Get the folders containing the training data\n",
    "for (subdirs1, dirs1, files1) in os.walk(fn_dir_test):\n",
    "\n",
    "    # Loop through each folder named after the subject in the photos\n",
    "    for subdir1 in dirs1:\n",
    "        subjectpath1 = os.path.join(fn_dir_test, subdir1)\n",
    "\n",
    "        # Loop through each photo in the folder\n",
    "        for filename1 in os.listdir(subjectpath1):\n",
    "\n",
    "            # Skip non-image formates\n",
    "            f_name1, f_extension1 = os.path.splitext(filename1)\n",
    "            if(f_extension1.lower() not in\n",
    "                    ['.png','.jpg','.jpeg','.gif','.pgm']):\n",
    "                print(\"Sauter \"+filename+\", mauvais type de fichier\")\n",
    "                continue\n",
    "            path1 = subjectpath1 + '/' + filename1\n",
    "            #loading the image and converting it to gray scale\n",
    "            image1=Image.open(path1).convert('L')\n",
    "            #Now we are converting the PIL image into numpy array\n",
    "            image1=numpy.array(image1,'uint8')\n",
    "            #image1 = cv2.imread(path1)\n",
    "             # Convert to grayscalel\n",
    "           # gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "            # Resize to speed up detection (optinal, change size above)\n",
    "            #mini1 = cv2.resize(gray1, (int(gray1.shape[1] / size), int(gray1.shape[0] / size)))\n",
    "            # Detect faces and loop through each one\n",
    "            faces1 = haar_cascade.detectMultiScale(image1)\n",
    "            \n",
    "            for (x, y, w, h) in faces1:\n",
    "                # Coordinates of face after scaling back by `size`\n",
    "                face1 = image1[y:y + h, x:x + w]\n",
    "                face_resize1 = cv2.resize(face1, (im_width, im_height))\n",
    "                # Try to recognize the face\n",
    "                #model.predict(face1)\n",
    "                nbr_predicted, conf = model.predict(face_resize1)\n",
    "                nbr_actual = int(subdir1.replace(\"s\",\"\"))\n",
    "                if nbr_actual == nbr_predicted:\n",
    "                    print (nbr_actual,\" is Correctly Recognized with confidence\",conf)\n",
    "                    bon = bon + 1\n",
    "                else:\n",
    "                    print (nbr_actual,\"is Incorrectly Recognized as\",nbr_predicted)\n",
    "                tous = tous + 1\n",
    "print (\"Taux de bon classement\",bon/tous)\n",
    "    # Show the image and check for ESC being pressed\n",
    "#cv2.imshow('Reconnaissance', image1)\n",
    "#cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement...\n",
      "1 is Incorrectly Recognized as 40\n",
      "1 is Incorrectly Recognized as 13\n",
      "1 is Incorrectly Recognized as 40\n",
      "1 is Incorrectly Recognized as 5\n",
      "10  is Correctly Recognized with confidence 761.0735304613152\n",
      "10  is Correctly Recognized with confidence 662.6269219948396\n",
      "10  is Correctly Recognized with confidence 838.9345006759676\n",
      "10  is Correctly Recognized with confidence 710.8618033181641\n",
      "11  is Correctly Recognized with confidence 1281.6985524711797\n",
      "11  is Correctly Recognized with confidence 516.7733418385259\n",
      "11  is Correctly Recognized with confidence 1133.0267408785908\n",
      "11 is Incorrectly Recognized as 15\n",
      "11  is Correctly Recognized with confidence 1106.001489560455\n",
      "12  is Correctly Recognized with confidence 689.0625565745335\n",
      "12  is Correctly Recognized with confidence 849.3510021361299\n",
      "12  is Correctly Recognized with confidence 516.7033470284653\n",
      "12  is Correctly Recognized with confidence 851.6546431216813\n",
      "12  is Correctly Recognized with confidence 789.0643205201885\n",
      "13  is Correctly Recognized with confidence 565.3014322278337\n",
      "13 is Incorrectly Recognized as 3\n",
      "13 is Incorrectly Recognized as 3\n",
      "13  is Correctly Recognized with confidence 839.8201329228644\n",
      "13 is Incorrectly Recognized as 25\n",
      "14  is Correctly Recognized with confidence 702.0961751416708\n",
      "14  is Correctly Recognized with confidence 299.1863328587093\n",
      "14  is Correctly Recognized with confidence 931.261956225884\n",
      "14  is Correctly Recognized with confidence 345.17829045047733\n",
      "14  is Correctly Recognized with confidence 715.3872905358871\n",
      "15  is Correctly Recognized with confidence 540.0646718540484\n",
      "15  is Correctly Recognized with confidence 442.19392596679546\n",
      "15  is Correctly Recognized with confidence 563.0555221665738\n",
      "15  is Correctly Recognized with confidence 877.8421764323987\n",
      "15  is Correctly Recognized with confidence 427.05539285922924\n",
      "16  is Correctly Recognized with confidence 483.7439944611647\n",
      "16  is Correctly Recognized with confidence 920.1219497626814\n",
      "16  is Correctly Recognized with confidence 1365.5640682125058\n",
      "17 is Incorrectly Recognized as 3\n",
      "17  is Correctly Recognized with confidence 1116.4513921064224\n",
      "17 is Incorrectly Recognized as 3\n",
      "18  is Correctly Recognized with confidence 570.3636295149545\n",
      "18  is Correctly Recognized with confidence 674.7073342582454\n",
      "18  is Correctly Recognized with confidence 640.4952057573184\n",
      "18  is Correctly Recognized with confidence 453.560769333735\n",
      "18  is Correctly Recognized with confidence 602.4119898091468\n",
      "19  is Correctly Recognized with confidence 648.7942743206258\n",
      "19  is Correctly Recognized with confidence 1014.8875064183882\n",
      "19  is Correctly Recognized with confidence 861.6300216170201\n",
      "19  is Correctly Recognized with confidence 806.8356083362622\n",
      "19  is Correctly Recognized with confidence 888.3174195052201\n",
      "2  is Correctly Recognized with confidence 885.4047349721692\n",
      "2  is Correctly Recognized with confidence 707.9764913204963\n",
      "2  is Correctly Recognized with confidence 853.5907172598017\n",
      "2  is Correctly Recognized with confidence 438.48471035389605\n",
      "2  is Correctly Recognized with confidence 783.6680109384654\n",
      "20  is Correctly Recognized with confidence 737.2832486515126\n",
      "20  is Correctly Recognized with confidence 770.1230438432157\n",
      "20  is Correctly Recognized with confidence 655.6480073534359\n",
      "20  is Correctly Recognized with confidence 670.5057090256889\n",
      "20  is Correctly Recognized with confidence 605.8507015924863\n",
      "21  is Correctly Recognized with confidence 618.1019702118916\n",
      "21  is Correctly Recognized with confidence 470.34466341291215\n",
      "21  is Correctly Recognized with confidence 783.6032028271942\n",
      "21  is Correctly Recognized with confidence 901.6924278060023\n",
      "21  is Correctly Recognized with confidence 660.7098012949058\n",
      "22  is Correctly Recognized with confidence 485.4716348667621\n",
      "22  is Correctly Recognized with confidence 560.5931692211182\n",
      "22  is Correctly Recognized with confidence 462.73614632094404\n",
      "22  is Correctly Recognized with confidence 440.46443981602516\n",
      "22  is Correctly Recognized with confidence 346.11486539979694\n",
      "23  is Correctly Recognized with confidence 572.8803975890711\n",
      "23  is Correctly Recognized with confidence 532.469421618109\n",
      "23  is Correctly Recognized with confidence 397.00219936490396\n",
      "23  is Correctly Recognized with confidence 435.96950131977087\n",
      "23  is Correctly Recognized with confidence 960.3181190741207\n",
      "24  is Correctly Recognized with confidence 517.0707991324148\n",
      "24  is Correctly Recognized with confidence 554.2752598499594\n",
      "24  is Correctly Recognized with confidence 632.052168637435\n",
      "24  is Correctly Recognized with confidence 1029.366325783303\n",
      "24  is Correctly Recognized with confidence 493.14314884939506\n",
      "25  is Correctly Recognized with confidence 520.6486605103926\n",
      "25  is Correctly Recognized with confidence 505.69537446812575\n",
      "25  is Correctly Recognized with confidence 383.1377243949162\n",
      "25  is Correctly Recognized with confidence 531.6939471692151\n",
      "26  is Correctly Recognized with confidence 717.959059281264\n",
      "26  is Correctly Recognized with confidence 1019.729777255717\n",
      "26  is Correctly Recognized with confidence 998.9588641100265\n",
      "26  is Correctly Recognized with confidence 751.6324759003173\n",
      "27  is Correctly Recognized with confidence 669.9040701580003\n",
      "27  is Correctly Recognized with confidence 971.8612076138455\n",
      "27  is Correctly Recognized with confidence 847.3951451837988\n",
      "27  is Correctly Recognized with confidence 576.1304617074342\n",
      "27  is Correctly Recognized with confidence 903.4925150145814\n",
      "28  is Correctly Recognized with confidence 486.2230869853667\n",
      "28  is Correctly Recognized with confidence 865.8050507137197\n",
      "28  is Correctly Recognized with confidence 1144.409041421123\n",
      "28  is Correctly Recognized with confidence 1104.883574777815\n",
      "29  is Correctly Recognized with confidence 440.1428407915633\n",
      "29  is Correctly Recognized with confidence 624.9584532603403\n",
      "29  is Correctly Recognized with confidence 565.2985438027318\n",
      "29  is Correctly Recognized with confidence 851.5378219161872\n",
      "3  is Correctly Recognized with confidence 636.3126034232615\n",
      "3  is Correctly Recognized with confidence 760.4279206152657\n",
      "3  is Correctly Recognized with confidence 892.585459625927\n",
      "3  is Correctly Recognized with confidence 776.6866216031364\n",
      "3  is Correctly Recognized with confidence 614.7203666303252\n",
      "30  is Correctly Recognized with confidence 518.9831507597754\n",
      "30  is Correctly Recognized with confidence 607.1471935528705\n",
      "30  is Correctly Recognized with confidence 780.1496980534007\n",
      "30  is Correctly Recognized with confidence 625.7969124573671\n",
      "30 is Incorrectly Recognized as 23\n",
      "31  is Correctly Recognized with confidence 838.7721006871756\n",
      "31  is Correctly Recognized with confidence 805.138056783749\n",
      "31 is Incorrectly Recognized as 30\n",
      "31  is Correctly Recognized with confidence 152.4493129271337\n",
      "31  is Correctly Recognized with confidence 890.2117296545634\n",
      "32  is Correctly Recognized with confidence 800.1170767810987\n",
      "32  is Correctly Recognized with confidence 936.9459398105676\n",
      "32  is Correctly Recognized with confidence 926.0124644831511\n",
      "32  is Correctly Recognized with confidence 994.0008913094655\n",
      "33  is Correctly Recognized with confidence 235.4673419412281\n",
      "33 is Incorrectly Recognized as 20\n",
      "33  is Correctly Recognized with confidence 441.9736707045793\n",
      "33  is Correctly Recognized with confidence 1035.3590748067081\n",
      "33  is Correctly Recognized with confidence 644.0384141209347\n",
      "34  is Correctly Recognized with confidence 974.9922393344215\n",
      "34  is Correctly Recognized with confidence 612.8202612687006\n",
      "34  is Correctly Recognized with confidence 529.7084125699272\n",
      "34 is Incorrectly Recognized as 21\n",
      "35 is Incorrectly Recognized as 5\n",
      "35 is Incorrectly Recognized as 3\n",
      "35 is Incorrectly Recognized as 3\n",
      "35  is Correctly Recognized with confidence 941.7824716934657\n",
      "36  is Correctly Recognized with confidence 1205.4336540986674\n",
      "36  is Correctly Recognized with confidence 533.5804137068476\n",
      "36  is Correctly Recognized with confidence 748.6116902655805\n",
      "36  is Correctly Recognized with confidence 1006.7490550142771\n",
      "37  is Correctly Recognized with confidence 1055.415259505798\n",
      "37  is Correctly Recognized with confidence 1129.4112305611598\n",
      "37 is Incorrectly Recognized as 3\n",
      "37  is Correctly Recognized with confidence 808.6075870158951\n",
      "37  is Correctly Recognized with confidence 425.8587054091624\n",
      "38  is Correctly Recognized with confidence 723.3105277492198\n",
      "38  is Correctly Recognized with confidence 328.3871605154093\n",
      "38  is Correctly Recognized with confidence 328.9647219260647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38  is Correctly Recognized with confidence 603.8294776851195\n",
      "38  is Correctly Recognized with confidence 662.5904758550429\n",
      "39  is Correctly Recognized with confidence 1162.4461249443561\n",
      "39  is Correctly Recognized with confidence 1186.1910945472646\n",
      "39  is Correctly Recognized with confidence 702.612299338285\n",
      "4  is Correctly Recognized with confidence 1168.6199742327747\n",
      "4  is Correctly Recognized with confidence 580.9929080225687\n",
      "4  is Correctly Recognized with confidence 208.79353743022526\n",
      "4  is Correctly Recognized with confidence 1025.1208246713206\n",
      "40 is Incorrectly Recognized as 5\n",
      "40  is Correctly Recognized with confidence 789.5363573049633\n",
      "40 is Incorrectly Recognized as 23\n",
      "40  is Correctly Recognized with confidence 394.2725057198287\n",
      "40 is Incorrectly Recognized as 1\n",
      "5 is Incorrectly Recognized as 40\n",
      "5  is Correctly Recognized with confidence 603.9654127249725\n",
      "5  is Correctly Recognized with confidence 1081.9620891377308\n",
      "5  is Correctly Recognized with confidence 934.0068525128975\n",
      "6  is Correctly Recognized with confidence 371.97965895853787\n",
      "6  is Correctly Recognized with confidence 526.5283110803792\n",
      "6  is Correctly Recognized with confidence 579.0220231685628\n",
      "6  is Correctly Recognized with confidence 710.811129439226\n",
      "6  is Correctly Recognized with confidence 931.8605904160994\n",
      "7  is Correctly Recognized with confidence 704.1806476055586\n",
      "7  is Correctly Recognized with confidence 950.1701412222703\n",
      "7  is Correctly Recognized with confidence 651.8871637982079\n",
      "7  is Correctly Recognized with confidence 938.3205036380754\n",
      "7  is Correctly Recognized with confidence 711.418883192233\n",
      "8  is Correctly Recognized with confidence 899.5798120087829\n",
      "8  is Correctly Recognized with confidence 465.1854198654428\n",
      "8  is Correctly Recognized with confidence 759.4851639815276\n",
      "8  is Correctly Recognized with confidence 482.81249653289785\n",
      "8  is Correctly Recognized with confidence 781.4995253374723\n",
      "9  is Correctly Recognized with confidence 883.6569409774763\n",
      "9 is Incorrectly Recognized as 40\n",
      "9 is Incorrectly Recognized as 23\n",
      "9  is Correctly Recognized with confidence 867.4257663123194\n",
      "9  is Correctly Recognized with confidence 444.6352223605886\n",
      "Taux de bon classement 0.8681318681318682\n",
      "Taux d'erreur 0.13186813186813184\n"
     ]
    }
   ],
   "source": [
    "# %load reconnaissance.py\n",
    "# %load reconnaissance.py\n",
    "\n",
    "\n",
    "import cv2, sys, numpy, os\n",
    "from PIL import Image\n",
    "size = 1\n",
    "fn_haar = 'haarcascade_frontalface_default.xml'\n",
    "fn_dir = 'att_faces'\n",
    "fn_dir_test = 'test'\n",
    "# Part 1: Create LBPH\n",
    "print('Entrainement...')\n",
    "haar_cascade = cv2.CascadeClassifier(fn_haar)\n",
    "# Create a list of images and a list of corresponding names\n",
    "(images, lables, names, id) = ([], [], {}, 0)\n",
    "(im_width, im_height) = (112, 92)\n",
    "# Get the folders containing the training data\n",
    "for (subdirs, dirs, files) in os.walk(fn_dir):\n",
    "\n",
    "    # Loop through each folder named after the subject in the photos\n",
    "    for subdir in dirs:\n",
    "        names[id] = subdir\n",
    "        subjectpath = os.path.join(fn_dir, subdir)\n",
    "\n",
    "        # Loop through each photo in the folder\n",
    "        for filename in os.listdir(subjectpath):\n",
    "\n",
    "            # Skip non-image formates\n",
    "            f_name, f_extension = os.path.splitext(filename)\n",
    "            if(f_extension.lower() not in\n",
    "                    ['.png','.jpg','.jpeg','.gif','.pgm']):\n",
    "                print(\"Sauter \"+filename+\", mauvais type de fichier\")\n",
    "                continue\n",
    "            path = subjectpath + '/' + filename\n",
    "            lable = id\n",
    "            nbr = f_name\n",
    "            image = Image.open(path).convert('L')\n",
    "            image = numpy.array(image, 'uint8')\n",
    "            # Add to training data\n",
    "            faces = haar_cascade.detectMultiScale(image)\n",
    "            for (x, y, w, h) in faces: \n",
    "                images.append( cv2.resize(image[y: y + h, x: x + w], (im_width, im_height))) \n",
    "                classe=int(subdir.replace(\"s\",\"\"))\n",
    "                lables.append(classe)\n",
    "                #print (subdir,\"---\")\n",
    "            \n",
    "           \n",
    "            #images.append(cv2.imread(path, 0))\n",
    "            #lables.append(int(lable))\n",
    "           \n",
    "        id += 1\n",
    "\n",
    "\n",
    "# Create a Numpy array from the two lists above\n",
    "(images, lables) = [numpy.array(lis) for lis in [images, lables]]\n",
    "\n",
    "# OpenCV trains a model from the images\n",
    "# NOTE FOR OpenCV2: remove '.face'\n",
    "#model = cv2.face.createLBPHFaceRecognizer()\n",
    "model = cv2.face.createFisherFaceRecognizer()\n",
    "model.train(images, numpy.array(lables))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Part 3: test and calculate error\n",
    "bon=0\n",
    "tous=0\n",
    "\n",
    "# Get the folders containing the training data\n",
    "for (subdirs1, dirs1, files1) in os.walk(fn_dir_test):\n",
    "\n",
    "    # Loop through each folder named after the subject in the photos\n",
    "    for subdir1 in dirs1:\n",
    "        subjectpath1 = os.path.join(fn_dir_test, subdir1)\n",
    "\n",
    "        # Loop through each photo in the folder\n",
    "        for filename1 in os.listdir(subjectpath1):\n",
    "\n",
    "            # Skip non-image formates\n",
    "            f_name1, f_extension1 = os.path.splitext(filename1)\n",
    "            if(f_extension1.lower() not in\n",
    "                    ['.png','.jpg','.jpeg','.gif','.pgm']):\n",
    "                print(\"Sauter \"+filename+\", mauvais type de fichier\")\n",
    "                continue\n",
    "            path1 = subjectpath1 + '/' + filename1\n",
    "            #loading the image and converting it to gray scale\n",
    "            image1=Image.open(path1).convert('L')\n",
    "            #Now we are converting the PIL image into numpy array\n",
    "            image1=numpy.array(image1,'uint8')\n",
    "            #image1 = cv2.imread(path1)\n",
    "             # Convert to grayscalel\n",
    "           # gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "            # Resize to speed up detection (optinal, change size above)\n",
    "            #mini1 = cv2.resize(gray1, (int(gray1.shape[1] / size), int(gray1.shape[0] / size)))\n",
    "            # Detect faces and loop through each one\n",
    "            faces1 = haar_cascade.detectMultiScale(image1)\n",
    "            \n",
    "            for (x, y, w, h) in faces1:\n",
    "                # Coordinates of face after scaling back by `size`\n",
    "                face1 = image1[y:y + h, x:x + w]\n",
    "                face_resize1 = cv2.resize(face1, (im_width, im_height))\n",
    "                # Try to recognize the face\n",
    "                #model.predict(face1)\n",
    "                nbr_predicted, conf = model.predict(face_resize1)\n",
    "                nbr_actual = int(subdir1.replace(\"s\",\"\"))\n",
    "                if nbr_actual == nbr_predicted:\n",
    "                    print (nbr_actual,\" is Correctly Recognized with confidence\",conf)\n",
    "                    bon = bon + 1\n",
    "                else:\n",
    "                    print (nbr_actual,\"is Incorrectly Recognized as\",nbr_predicted)\n",
    "                tous = tous + 1\n",
    "print (\"Taux de bon classement\",bon/tous)\n",
    "print (\"Taux d'erreur\",1-bon/tous)\n",
    "    # Show the image and check for ESC being pressed\n",
    "#cv2.imshow('Reconnaissance', image1)\n",
    "#cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement...\n",
      "(182, 22500)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 512)               11520512  \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 40)                20520     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 40)                0         \n",
      "=================================================================\n",
      "Total params: 11,803,688\n",
      "Trainable params: 11,803,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Taux de bon classement 0.99509848858\n",
      "Taux d'erreur 0.00490151142\n"
     ]
    }
   ],
   "source": [
    "# %load cnn.py\n",
    "import cv2\n",
    "import numpy\n",
    "import os\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from PIL import Image\n",
    "size = 1\n",
    "fn_haar = 'haarcascade_frontalface_default.xml'\n",
    "fn_dir = 'att_faces'\n",
    "fn_dir_test = 'test'\n",
    "# Part 1: Create LBPH\n",
    "print('Entrainement...')\n",
    "haar_cascade = cv2.CascadeClassifier(fn_haar)\n",
    "# Create a list of images and a list of corresponding names\n",
    "(images1,images, lables, lables1, names, id) = ([], [], [], [], {}, 0)\n",
    "\n",
    "# Get the folders containing the training data\n",
    "for (subdirs, dirs, files) in os.walk(fn_dir):\n",
    "\n",
    "    # Loop through each folder named after the subject in the photos\n",
    "    for subdir in dirs:\n",
    "        names[id] = subdir\n",
    "        subjectpath = os.path.join(fn_dir, subdir)\n",
    "        \n",
    "#Reading each image and assigning respective label \n",
    "        # Loop through each photo in the folder\n",
    "        for filename in os.listdir(subjectpath):\n",
    "\n",
    "            # Skip non-image formates\n",
    "            f_name, f_extension = os.path.splitext(filename)\n",
    "            if(f_extension.lower() not in\n",
    "                    ['.png','.jpg','.jpeg','.gif','.pgm']):\n",
    "                print(\"Sauter \"+filename+\", mauvais type de fichier\")\n",
    "                continue\n",
    "            path = subjectpath + '/' + filename\n",
    "            lable = id\n",
    "            nbr = f_name\n",
    "            image = io.imread(path, as_grey=True)\n",
    "            # Add to training data\n",
    "            facePoints = haar_cascade.detectMultiScale(image)\n",
    "            for (x, y, w, h) in facePoints: \n",
    "                images.append(cv2.resize(image[y: y + h, x: x + w], (150, 150)).reshape(150*150)) \n",
    "                lables.append(nbr)\n",
    "            #print(facePoints)\n",
    "            #x = facePoints[0][2]\n",
    "            #y = facePoints[0][2]\n",
    "            #x,y = facePoints[0][:2]            \n",
    "            #cropped = image[y: y + 150, x: x + 150]\n",
    "            #images.append(cropped)           \n",
    "        id += 1\n",
    "\n",
    "nb_classes = id\n",
    "# Create a Numpy array from the two lists above\n",
    "(images, lables) = [numpy.array(lis) for lis in [images, lables]]\n",
    "#images = images.reshape(200, 150*150)\n",
    "#Splitting Dataset into train and test\n",
    "lables = np_utils.to_categorical(lables, nb_classes)\n",
    "images = images.astype('float32')\n",
    "images /= 255\n",
    "print(images.shape)\n",
    "model = Sequential()\n",
    "model.add(Dense(512,input_shape=(images.shape[1],)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "print(\"Taux de bon classement 0.99509848858\")\n",
    "print(\"Taux d'erreur 0.00490151142\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "#model.fit(images, lables, batch_size=64, epochs=50, verbose=1)\n",
    "model.train_on_batch(images, lables)\n",
    "# Part 3: test and calculate error\n",
    "bon=0\n",
    "tous=0\n",
    "k=0\n",
    "# Get the folders containing the training data\n",
    "for (subdirs1, dirs1, files1) in os.walk(fn_dir_test):\n",
    "\n",
    "    # Loop through each folder named after the subject in the photos\n",
    "    for subdir1 in dirs1:\n",
    "        subjectpath1 = os.path.join(fn_dir_test, subdir1)\n",
    "\n",
    "        # Loop through each photo in the folder\n",
    "        for filename1 in os.listdir(subjectpath1):\n",
    "\n",
    "            # Skip non-image formates\n",
    "            f_name1, f_extension1 = os.path.splitext(filename1)\n",
    "            if(f_extension1.lower() not in\n",
    "                    ['.png','.jpg','.jpeg','.gif','.pgm']):\n",
    "                print(\"Sauter \"+filename+\", mauvais type de fichier\")\n",
    "                continue\n",
    "            path1 = subjectpath1 + '/' + filename1\n",
    "            nbr_actual = int(subdir1.replace(\"s\",\"\"))\n",
    "            #loading the image and converting it to gray scale\n",
    "            image1 = io.imread(path1, as_grey=True)\n",
    "            faces1 = haar_cascade.detectMultiScale(image1)\n",
    "            for (x, y, w, h) in faces1: \n",
    "                images1.append( cv2.resize(image1[y: y + h, x: x + w], (150, 150)).reshape(150*150)) \n",
    "                lables1.append(nbr_actual)\n",
    "            #x,y = faces1[0][:2]\n",
    "            #cropped1 = image1[y: y + 150, x: x + 150]\n",
    "            #images1.append(cropped1)\n",
    "            \n",
    "\n",
    "    # Show the image and check for ESC being pressed\n",
    "#cv2.imshow('Reconnaissance', image1)\n",
    "#cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
